✅ 1. On an internet-connected machine
Step 1: Create a folder
bash
Copy
Edit
mkdir pytorch-cu121-offline
cd pytorch-cu121-offline
Step 2: Download .whl files
Use pip download to fetch all necessary packages:

bash
Copy
Edit
pip download torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
This will download files like:

torch-2.x.x+cu121-cp38-cp38-linux_x86_64.whl

torchvision-0.x.x+cu121-cp38-cp38-linux_x86_64.whl

torchaudio-0.x.x+cu121-cp38-cp38-linux_x86_64.whl

Plus any dependencies (e.g., typing_extensions, numpy, etc.)

✅ 2. Copy files to your VM
From your local machine:

bash
Copy
Edit
scp *.whl root@10.107.163.176:/root/pytorch-cu121/
Or zip them first:

bash
Copy
Edit
zip -r pytorch-cu121.zip pytorch-cu121-offline/
scp pytorch-cu121.zip root@10.107.163.176:/root/
Then on the VM:

bash
Copy
Edit
unzip pytorch-cu121.zip
cd pytorch-cu121-offline
✅ 3. On the RHEL VM: Install Offline
Install with pip (no internet needed)
bash
Copy
Edit
cd /root/pytorch-cu121-offline
pip install *.whl
⚠️ Make sure you use pip3 if your default pip is Python 2.x:

bash
Copy
Edit
pip3 install *.whl
✅ 4. Test PyTorch with CUDA on the VM
bash
Copy
Edit
python3
Run this:

python
Copy
Edit
import torch
print(torch.cuda.is_available())
print(torch.cuda.get_device_name(0))
print(torch.__version__)
Expected output:

graphql
Copy
Edit
True
NVIDIA H100 80GB HBM3
2.x.x
Let me know if you want me to:

Send you the direct .whl file URLs

Or script this into a zip bundle for your environment (Python 3.6/3.8/3.9, etc.)

Also confirm your Python version on the VM:

bash
Copy
Edit
python3 --version
