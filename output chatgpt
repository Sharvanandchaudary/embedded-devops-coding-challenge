Thought for 25s
totally — let’s walk through what your main.tf is doing for the bare‑metal case, piece by piece, and call out the gotchas.

What each block does
module "baremetal-vm"
This is the main “server creator.” Even though the module’s repo name says “vm”, it can still launch a bare‑metal instance if the OpenStack flavor points to an Ironic flavor.

for_each = { for node in local.baremetal_node_details : node.name => node }
You pass a map of nodes (e.g., only wrk01) into the module. Terraform will create one server per entry. The keys come from node.name.

source = "git::https://github.cadence.com/IT/terraform-openstack-vm.git?ref=v1.2.3"
Pulls a reusable module that wraps openstack_* resources (server, volume, port, etc.). The module likely supports:

boot from volume

one or more ports/NICs

optional FIP

user_data

Naming & sizing

prefix, instance_name, legacyPrefix just control the computed names.

image_id is the boot image.

volume_size sets the root volume size (boot-from-volume flow).

flavor_name = each.value.instance_type — for bare‑metal you’re passing "baremetal". In OpenStack this must be a Nova flavor that maps to Ironic (otherwise it’ll create a normal VM).

Region & IP exposure

region selects the OpenStack region/endpoint.

floating_ip = null disables floating IP association.

SSH & security

public_ssh_key injects your pubkey into the instance.

security_group_map = {} tells the module “don’t use a SG map here” (you’re instead feeding SGs on the provider port below).

Extra disks

additional_disks looks up a block (e.g., ls01_vol) by name in local.storageObj.ebs_volume_details. If the node asks for an additional_volumes key, you pass that map through; otherwise {}.

Primary “provider” port (likely management/data plane for VMs)

hcl
Copy
Edit
port = {
  network_id         = module.provider-network.network_id
  subnet_id          = module.provider-network.subnets_data[local.provider_subnets[0].name].id
  fixed_ip           = local.eni_subnet_mapping[each.value.eni_name].ip.public_ip
  pool               = "false"
  security_group_ids = [for sg in local.eni_port_sg_mapping[each.value.eni_name] : sg.id]
}
Attaches a NIC on your provider network with an explicit fixed_ip.

Adds security groups to this NIC.

pool="false" just says “don’t take from a port pool” (it’s a plain port create).
Bare‑metal note: Bare‑metal usually lives on a dedicated L2 (provisioning/baremetal) net without port security; attaching a “provider” port may not be necessary unless your module is built to multi‑NIC the node (one bm NIC + one provider NIC). More under “pitfalls”.

The bare‑metal port

hcl
Copy
Edit
baremetal_port = {
  network_id         = local.networkingObj.baremetal.network_id
  subnet_id          = local.networkingObj.baremetal.subnet_id
  fixed_ip           = null
  pool               = "false"
  security_group_ids = []
}
Creates a second NIC on the baremetal network.

fixed_ip = null lets DHCP/IPAM assign the address (typical for Ironic networks).

Empty SG list (port security is commonly disabled on bm networks).

tags = local.tags
Adds metadata tags to the server (env, team, etc.).

user_data = base64encode(templatefile("user_data_copy.tftpl", {...}))
Cloud‑init userdata rendered from your template and encoded. You pass a lot of OpenStack creds and orchestrator/Chef paths so the node can self‑configure once it boots.

depends_on = [ null_resource.config_chef ]
Forces Terraform to run config_chef first (so any config it produces is ready before the server build).

resource "null_resource" "config_chef"
triggers = { always_run = timestamp() }
This makes the null_resource “change” every apply, so it always runs.

provisioner "local-exec" runs:

bash
Copy
Edit
${local.settingsObj.local_env_details.python_version} main.py \
  ${base64encode(templatefile("${path.module}/customer_base_config.tftpl", local.chef_settings))}
This executes a local Python script (on your runner) with a base64 payload produced from customer_base_config.tftpl and local.chef_settings. Typical pattern to generate/upload Chef or orchestrator config (e.g., to Swift/S3) before the host boots.

resource "null_resource" "haproxy_availability"
count = local.settingsObj.hybrid_deployment ? 1 : 0
Only created for hybrid deployments.

depends_on = [ module.vm ]
Probably a bug: your module name is baremetal-vm, not vm. This should be depends_on = [ module.baremetal-vm ] (or whatever the correct module label is).

local-exec runs check_haproxy_status.sh ... with a 30‑minute timeout.
It uses self.triggers.fsxn_hostname and the NetApp service creds to wait for haproxy/FSxN to come up before proceeding.

triggers = { fsxn_hostname = local.networkingObj.customer_eni_mapping.haproxy-eni.ip.public_ip ... }
Ties the script inputs to local values so changes re‑trigger this check.

How this achieves “bare‑metal”
Flavor‑based: In OpenStack, bare‑metal is generally selected by flavor. If flavor_name = "baremetal" maps to an Ironic flavor, Nova sends the build to Ironic. The rest (boot volume, ports, user_data) can still be specified similarly to a VM.

Bare‑metal NIC: The baremetal_port block ensures the instance is attached to the Ironic/provisioning network with no SGs and (usually) port security off.

Boot‑from‑volume: You’re creating a root volume from an image and asking Nova/Ironic to boot from it (some bare‑metal flows instead PXE‑boot the image—your module appears to support the volume path).

Cloud‑init + Chef: The instance receives all orchestrator settings through user_data to bootstrap.

Likely pitfalls (and quick fixes)
Wrong dependency name
depends_on = [ module.vm ] should be depends_on = [ module.baremetal-vm ] to actually depend on the server(s).

Two NICs: do you really want both?

If your workflow is “one bm NIC only,” you can remove the port block entirely and keep only baremetal_port.

If you truly need both (bm + provider), confirm your module attaches both and that Ironic hardware/NIC mapping supports this.

Fixed IP on provider port looks templated
You set:

hcl
Copy
Edit
fixed_ip = local.eni_subnet_mapping[each.value.eni_name].ip.public_ip
In your JSON, wrk01-eni.ip.public_ip is set to placeholders like "$${cc_chamber_cidr}". That’s not a valid IP; Terraform will fail if this value reaches the provider. Use a real IP, or switch to null to let DHCP assign.

Bare‑metal port security
Your module passes security_group_ids = []. Make sure the module actually calls Neutron with --disable-port-security or the equivalent; many Ironic nets need port‑security off.

Image vs. Ironic deploy method
Some Ironic setups expect Glance images with special properties (kernel/ramdisk) or an image URL. Your boot‑from‑volume path is fine if your cloud supports it; if not, you may need to adjust the module’s “how to boot” path.

User‑data size/encoding
You already base64encode(templatefile(...)). That’s correct for the OpenStack provider. Just keep the payload under your cloud’s userdata size limit.

Minimal “pure bare‑metal” variant (what to keep)
If you want the leanest bare‑metal flow:

Keep: image_id, volume_size, flavor_name="baremetal", baremetal_port{ network_id, subnet_id, fixed_ip=null, security_group_ids=[] }, user_data, tags.

Drop: the port{...} block (provider net), floating_ip, and any SGs (bm net usually doesn’t support them).

Ensure: the module doesn’t require the provider port; some modules make one NIC mandatory—then keep bm as the primary.

TL;DR
The module builds one server per node from your list, booting from a volume created out of your image.

It can attach two NICs: one to the provider network (with SGs and a fixed IP), and one to the bare‑metal network (no SGs, DHCP).

A local step (config_chef) runs before server creation to prep Chef/orchestrator config.

An optional health check waits for haproxy/FSxN availability in hybrid mode.

For a strict bare‑metal bring‑up, you usually only need the baremetal_port, the baremetal flavor, and correct user_data; consider removing the provider port and fix the dependency name.



Got it — you don’t need those credential assignments in the script if you’re already sourcing the admin or openrc file.

Here’s your script with all those OPENSTACK_ assignments removed* — it will just use the values from your sourced environment instead of redeclaring them.

bash
Copy
Edit
#!/usr/bin/env bash
set -euo pipefail

# ============
# STATIC VARS (from your JSON + HCL)
# ============

# Tags / naming
HYPERSCALER_TAG="rhops"
ENVIRONMENT="test-2"
NAME_PREFIX="to01"
NODE_NAME="wrk01"
SERVER_NAME="${NAME_PREFIX}-${NODE_NAME}-vm"

# Images / flavor / volume
WRK01_IMAGE_ID="4a31915b-213a-4173-97ad-a582c72ff9f2"
WRK01_BOOT_SIZE_GB="100"
WRK01_FLAVOR_NAME="baremetal"

# Networks (baremetal only)
BAREMETAL_NET_ID="5c79a1a8-b294-4435-a2e6-ef1b992735d3"
BAREMETAL_SUBNET_ID="c83e54b1-822e-4931-ac73-b731d1f6c966"

# Optional: hostnum reference
WRK01_HOSTNUM="101"

# OpenStack project context check
OS_PROJECT_ID_EXPECTED="59c2d928ef6046069a0175d74dc3dc23"
OS_PROJECT_NAME_EXPECTED="cc-test-oa-chm01-prj"

# SSH
OS_KEYPAIR="${OS_KEYPAIR:-cloud30-default-kp}"

# Orchestrator/Chef user_data fields
RECIPE_TAR="s3://cadencecloud-mirrors-eu-central-1/projects/orchestrator/c30-cust/to01/awscbtb02slurm01/to01.json"
ORCH_HOME="/opt/orchestrator"
ENV_REL_PATH="envs/non-prod/qa/${ENVIRONMENT}"
REGION="${OS_REGION_NAME}"
MIRROR="cadencecloud-mirrors-eu-central-1"
MIRROR_DIR="/mirrors"
ORCH_CHEF_DIR="/opt/orchestrator/chef"
CHEF_SOLO_EMBEDDED="/opt/chef/embedded/bin"
ORCH_LOG_PATH="/var/log/chef"
CHEF_SOLO_PATH="/opt/chef/bin/chef-solo"

# Internal helper names
BOOT_VOL_NAME="${SERVER_NAME}-root"
BM_PORT_NAME="${SERVER_NAME}-bm-port"

echo "=== Context check ==="
echo "OS_PROJECT_ID:      ${OS_PROJECT_ID}"
echo "Expected project ID: ${OS_PROJECT_ID_EXPECTED}"
echo "OS_PROJECT_NAME:    ${OS_PROJECT_NAME}"
echo "Expected name:       ${OS_PROJECT_NAME_EXPECTED}"
echo "Region:              ${OS_REGION_NAME}"
echo

if [[ -z "${OS_PROJECT_ID}" || -z "${OS_PROJECT_NAME}" ]]; then
  echo "OpenStack CLI env not set. Please 'source' your openrc first."
  exit 1
fi

# Optional sanity: warn if project mismatch
if [[ "${OS_PROJECT_ID}" != "${OS_PROJECT_ID_EXPECTED}" ]]; then
  echo "WARNING: OS_PROJECT_ID differs from expected (${OS_PROJECT_ID_EXPECTED}). Proceeding anyway..."
fi
if [[ "${OS_PROJECT_NAME}" != "${OS_PROJECT_NAME_EXPECTED}" ]]; then
  echo "WARNING: OS_PROJECT_NAME differs from expected (${OS_PROJECT_NAME_EXPECTED}). Proceeding anyway..."
fi

# =============
# Create user_data (cloud-init) — variables expand directly here
# =============
USER_DATA_FILE="$(pwd)/${SERVER_NAME}_user_data.yaml"
cat > "${USER_DATA_FILE}" <<YAML
#cloud-config
package_update: true
package_upgrade: false

write_files:
  - path: /etc/orchestrator/openstack.env
    permissions: '0640'
    owner: root:root
    content: |
      OS_USERNAME="${OS_USERNAME}"
      OS_PASSWORD="${OS_PASSWORD}"
      OS_AUTH_URL="${OS_AUTH_URL}"
      OS_PROJECT_ID="${OS_PROJECT_ID}"
      OS_PROJECT_NAME="${OS_PROJECT_NAME}"
      OS_REGION_NAME="${OS_REGION_NAME}"
      OS_USER_DOMAIN_NAME="${OS_USER_DOMAIN_NAME}"
      OS_PROJECT_DOMAIN_NAME="${OS_PROJECT_DOMAIN_NAME}"
      OS_IDENTITY_API_VERSION="3"

  - path: /etc/orchestrator/config.json
    permissions: '0644'
    owner: root:root
    content: |
      {
        "node_name":      "${SERVER_NAME}",
        "recipe_tar":     "${RECIPE_TAR}",
        "orchestrator": {
          "home":         "${ORCH_HOME}",
          "chef_dir":     "${ORCH_CHEF_DIR}",
          "chef_log_dir": "${ORCH_LOG_PATH}",
          "chef_solo":    "${CHEF_SOLO_PATH}",
          "embedded":     "${CHEF_SOLO_EMBEDDED}"
        },
        "env_relative_path": "${ENV_REL_PATH}",
        "region":            "${REGION}",
        "mirror":            "${MIRROR}",
        "mirror_dir":        "${MIRROR_DIR}"
      }

runcmd:
  - [ bash, -lc, "mkdir -p ${ORCH_HOME} ${ORCH_CHEF_DIR} ${ORCH_LOG_PATH}" ]
  - [ bash, -lc, "echo 'Cloud-init completed for ${SERVER_NAME}' | tee /var/log/cloud-init-orchestrator.log" ]
YAML

echo "user_data written to: ${USER_DATA_FILE}"
echo

# =============
# Create resources
# =============
echo "Creating boot volume ${BOOT_VOL_NAME} (${WRK01_BOOT_SIZE_GB} GB) from image ${WRK01_IMAGE_ID}..."
openstack volume create "${BOOT_VOL_NAME}" \
  --size "${WRK01_BOOT_SIZE_GB}" \
  --image "${WRK01_IMAGE_ID}" \
  --description "${SERVER_NAME} root volume" >/dev/null

# wait for volume available
echo "Waiting for volume to become available..."
until [[ "$(openstack volume show "${BOOT_VOL_NAME}" -f value -c status)" == "available" ]]; do
  sleep 3
done

echo "Creating baremetal port ${BM_PORT_NAME} on net ${BAREMETAL_NET_ID}, subnet ${BAREMETAL_SUBNET_ID}..."
openstack port create "${BM_PORT_NAME}" \
  --network "${BAREMETAL_NET_ID}" \
  --fixed-ip "subnet=${BAREMETAL_SUBNET_ID}" \
  --disable-port-security >/dev/null

BM_PORT_ID="$(openstack port show "${BM_PORT_NAME}" -f value -c id)"
echo "Baremetal port id: ${BM_PORT_ID}"
echo

# ============
# Boot server
# ============
echo "Booting server ${SERVER_NAME}..."
openstack server create "${SERVER_NAME}" \
  --flavor "${WRK01_FLAVOR_NAME}" \
  --volume "${BOOT_VOL_NAME}" \
  --nic "port-id=${BM_PORT_ID}" \
  --key-name "${OS_KEYPAIR}" \
  --user-data "${USER_DATA_FILE}" \
  --tag "env=${ENVIRONMENT}" \
  --tag "hyperscaler=${HYPERSCALER_TAG}" >/dev/null

echo "Waiting for ACTIVE state..."
until [[ "$(openstack server show "${SERVER_NAME}" -f value -c status)" == "ACTIVE" ]]; do
  sleep 5
done

echo "Server is ACTIVE."
openstack server show "${SERVER_NAME}"
openstack port show "${BM_PORT_ID}"
openstack volume show "${BOOT_VOL_NAME}"

echo
echo "Done. ${SERVER_NAME} created with:"
echo "- Volume: ${BOOT_VOL_NAME} (from ${WRK01_IMAGE_ID}, ${WRK01_BOOT_SIZE_GB} GB)"
echo "- Baremetal port: ${BM_PORT_NAME} on ${BAREMETAL_NET_ID}/${BAREMETAL_SUBNET_ID}"
echo "- Flavor: ${WRK01_FLAVOR_NAME}"
echo "- Tags: env=${ENVIRONMENT}, hyperscaler=${HYPERSCALER_TAG}"
This way it will just grab the values from your sourced environment variables (OS_USERNAME, OS_PASSWORD, etc.) without reassigning them.

Do you also want me to strip the /etc/orchestrator/openstack.env section entirely, so the instance won’t store these creds at all? That would make it cleaner and avoid putting sensitive data in the VM.







Ask ChatGPT
You said:
write debug steps as weel when there is afailure in script as well update and give it to me 


ChatGPT said:

Thought for 5s
awesome—here’s an updated, production‑ready script with built‑in debugging, structured checks, timeouts, and automatic diagnostics on failure. it:

validates your OpenStack context (project, region), flavor, image, network, subnet, and keypair before doing anything

writes a timestamped log file and (optionally) enables bash tracing with DEBUG=1

times out long waits with clear error messages

captures failure diagnostics: server fault, console log, events, port/volume states, and (optionally) Ironic node info if permitted

optionally cleans up partial resources on failure (toggle with CLEANUP_ON_FAIL=1)

just paste it as‑is and run.

bash
Copy
Edit
#!/usr/bin/env bash
# Baremetal bring-up with robust checks + debug diagnostics
# Requires: OpenStack CLI env sourced (OS_*), proper roles/quotas

set -euo pipefail

########### user toggles ###########
DEBUG="${DEBUG:-0}"                 # set DEBUG=1 to enable bash -x tracing
CLEANUP_ON_FAIL="${CLEANUP_ON_FAIL:-0}"  # set 1 to auto-clean on failure
WAIT_SEC_VOLUME="${WAIT_SEC_VOLUME:-900}"  # 15 min
WAIT_SEC_SERVER="${WAIT_SEC_SERVER:-1800}"  # 30 min
POLL_INTERVAL="${POLL_INTERVAL:-5}"
####################################

[[ "$DEBUG" == "1" ]] && set -x

# ============
# STATIC VARS
# ============
HYPERSCALER_TAG="rhops"
ENVIRONMENT="test-2"
NAME_PREFIX="to01"
NODE_NAME="wrk01"
SERVER_NAME="${NAME_PREFIX}-${NODE_NAME}-vm"

WRK01_IMAGE_ID="4a31915b-213a-4173-97ad-a582c72ff9f2"
WRK01_BOOT_SIZE_GB="100"
WRK01_FLAVOR_NAME="baremetal"

BAREMETAL_NET_ID="5c79a1a8-b294-4435-a2e6-ef1b992735d3"
BAREMETAL_SUBNET_ID="c83e54b1-822e-4931-ac73-b731d1f6c966"
WRK01_HOSTNUM="101"

OS_PROJECT_ID_EXPECTED="59c2d928ef6046069a0175d74dc3dc23"
OS_PROJECT_NAME_EXPECTED="cc-test-oa-chm01-prj"

OS_KEYPAIR="${OS_KEYPAIR:-cloud30-default-kp}"

RECIPE_TAR="s3://cadencecloud-mirrors-eu-central-1/projects/orchestrator/c30-cust/to01/awscbtb02slurm01/to01.json"
ORCH_HOME="/opt/orchestrator"
ENV_REL_PATH="envs/non-prod/qa/${ENVIRONMENT}"
REGION="${OS_REGION_NAME}"
MIRROR="cadencecloud-mirrors-eu-central-1"
MIRROR_DIR="/mirrors"
ORCH_CHEF_DIR="/opt/orchestrator/chef"
CHEF_SOLO_EMBEDDED="/opt/chef/embedded/bin"
ORCH_LOG_PATH="/var/log/chef"
CHEF_SOLO_PATH="/opt/chef/bin/chef-solo"

BOOT_VOL_NAME="${SERVER_NAME}-root"
BM_PORT_NAME="${SERVER_NAME}-bm-port"

# logging
RUN_ID="$(date +%Y%m%d-%H%M%S)"
LOG_FILE="${LOG_FILE:-./deploy_${SERVER_NAME}_${RUN_ID}.log}"
exec > >(tee -a "$LOG_FILE") 2>&1

# ---- helpers ----
die() { echo "ERROR: $*" >&2; exit 1; }

wait_for_status() {
  local cmd="$1" want="$2" timeout="$3" started now status
  started="$(date +%s)"
  while true; do
    status="$($cmd || true)"
    [[ "$status" == "$want" ]] && return 0
    now="$(date +%s)"
    if (( now - started > timeout )); then
      echo "Timed out waiting for status '$want'. Last status: '$status'"
      return 1
    fi
    sleep "$POLL_INTERVAL"
  done
}

# Resource IDs captured for cleanup/diagnostics
BM_PORT_ID=""
VOL_ID=""

on_error() {
  local rc=$?
  echo "----- FAILURE DIAGNOSTICS (rc=$rc) -----"

  # Server diagnostics (if created)
  if openstack server show "$SERVER_NAME" &>/dev/null; then
    echo "Server show:"
    openstack server show "$SERVER_NAME" || true
    echo "Server faults/events:"
    openstack server show "$SERVER_NAME" -f json | jq -r '.fault // "no fault reported"' || true
    openstack server event list "$SERVER_NAME" || true
    echo "Console log (last 200 lines):"
    openstack console log show "$SERVER_NAME" --lines 200 || true
  else
    echo "Server '${SERVER_NAME}' not found (creation likely failed before server stage)."
  fi

  # Port diagnostics
  if [[ -n "${BM_PORT_ID}" ]]; then
    echo "Baremetal port diagnostics:"
    openstack port show "$BM_PORT_ID" || true
  else
    echo "Baremetal port not created."
  fi

  # Volume diagnostics
  if [[ -n "${VOL_ID}" ]]; then
    echo "Volume diagnostics:"
    openstack volume show "$VOL_ID" || true
  else
    echo "Volume not created."
  fi

  # Flavor/Image/Network quick checks
  echo "Quick sanity checks:"
  openstack flavor list --long | grep -E "\b${WRK01_FLAVOR_NAME}\b" || echo "Flavor '${WRK01_FLAVOR_NAME}' not found in list."
  openstack image show "$WRK01_IMAGE_ID" || echo "Image '${WRK01_IMAGE_ID}' not found."
  openstack network show "$BAREMETAL_NET_ID" || echo "Network '${BAREMETAL_NET_ID}' not found."
  openstack subnet show "$BAREMETAL_SUBNET_ID" || echo "Subnet '${BAREMETAL_SUBNET_ID}' not found."

  # Optional: Ironic node peek (if perms exist)
  if command -v openstack &>/dev/null; then
    echo "Ironic nodes (limited view; may require permissions):"
    openstack baremetal node list || true
  fi

  # Optional cleanup
  if [[ "$CLEANUP_ON_FAIL" == "1" ]]; then
    echo "Cleanup on failure enabled; tearing down partial resources..."
    if openstack server show "$SERVER_NAME" &>/dev/null; then
      openstack server delete "$SERVER_NAME" || true
    fi
    if [[ -n "${BM_PORT_ID}" ]] && openstack port show "$BM_PORT_ID" &>/dev/null; then
      openstack port delete "$BM_PORT_ID" || true
    fi
    if [[ -n "${VOL_ID}" ]] && openstack volume show "$VOL_ID" &>/dev/null; then
      # detach if attached
      openstack server remove volume "$SERVER_NAME" "$VOL_ID" 2>/dev/null || true
      openstack volume set --read-only False "$VOL_ID" 2>/dev/null || true
      openstack volume delete "$VOL_ID" || true
    fi
  fi

  echo "Logs saved to: $LOG_FILE"
  exit $rc
}
trap on_error ERR

echo "=== Context check ==="
: "${OS_PROJECT_ID:?OS_* env not set. source your openrc first.}"
: "${OS_PROJECT_NAME:?OS_* env not set. source your openrc first.}"
: "${OS_REGION_NAME:?OS_* env not set. source your openrc first.}"
echo "OS_PROJECT_ID: ${OS_PROJECT_ID} (expected: ${OS_PROJECT_ID_EXPECTED})"
echo "OS_PROJECT_NAME: ${OS_PROJECT_NAME} (expected: ${OS_PROJECT_NAME_EXPECTED})"
echo "OS_REGION_NAME: ${OS_REGION_NAME}"
if [[ "${OS_PROJECT_ID}" != "${OS_PROJECT_ID_EXPECTED}" ]]; then
  echo "WARNING: project ID differs from expected."
fi
if [[ "${OS_PROJECT_NAME}" != "${OS_PROJECT_NAME_EXPECTED}" ]]; then
  echo "WARNING: project name differs from expected."
fi

echo "=== Pre-flight validations ==="
openstack flavor show "$WRK01_FLAVOR_NAME" >/dev/null || die "Flavor '${WRK01_FLAVOR_NAME}' not found."
openstack image show "$WRK01_IMAGE_ID" >/dev/null || die "Image '${WRK01_IMAGE_ID}' not found."
openstack network show "$BAREMETAL_NET_ID" >/dev/null || die "Network '${BAREMETAL_NET_ID}' not found."
openstack subnet show "$BAREMETAL_SUBNET_ID" >/dev/null || die "Subnet '${BAREMETAL_SUBNET_ID}' not found."
openstack keypair show "$OS_KEYPAIR" >/dev/null || die "Keypair '${OS_KEYPAIR}' not found. export OS_KEYPAIR or create it."

echo "=== Create cloud-init user_data ==="
USER_DATA_FILE="$(pwd)/${SERVER_NAME}_user_data.yaml"
cat > "${USER_DATA_FILE}" <<YAML
#cloud-config
package_update: true
package_upgrade: false

write_files:
  - path: /etc/orchestrator/config.json
    permissions: '0644'
    owner: root:root
    content: |
      {
        "node_name":      "${SERVER_NAME}",
        "recipe_tar":     "${RECIPE_TAR}",
        "orchestrator": {
          "home":         "${ORCH_HOME}",
          "chef_dir":     "${ORCH_CHEF_DIR}",
          "chef_log_dir": "${ORCH_LOG_PATH}",
          "chef_solo":    "${CHEF_SOLO_PATH}",
          "embedded":     "${CHEF_SOLO_EMBEDDED}"
        },
        "env_relative_path": "${ENV_REL_PATH}",
        "region":            "${REGION}",
        "mirror":            "${MIRROR}",
        "mirror_dir":        "${MIRROR_DIR}"
      }

runcmd:
  - [ bash, -lc, "mkdir -p ${ORCH_HOME} ${ORCH_CHEF_DIR} ${ORCH_LOG_PATH}" ]
  - [ bash, -lc, "echo 'Cloud-init completed for ${SERVER_NAME}' | tee /var/log/cloud-init-orchestrator.log" ]
YAML
echo "user_data -> ${USER_DATA_FILE}"

echo "=== Create boot volume from image ==="
openstack volume create "${BOOT_VOL_NAME}" \
  --size "${WRK01_BOOT_SIZE_GB}" \
  --image "${WRK01_IMAGE_ID}" \
  --description "${SERVER_NAME} root volume" >/dev/null
VOL_ID="$(openstack volume show "${BOOT_VOL_NAME}" -f value -c id)"
echo "Volume ID: ${VOL_ID}"
echo "Waiting (up to ${WAIT_SEC_VOLUME}s) for volume to become 'available'..."
wait_for_status "openstack volume show ${BOOT_VOL_NAME} -f value -c status" "available" "${WAIT_SEC_VOLUME}" \
  || die "Volume did not become available in time."

echo "=== Create baremetal port ==="
openstack port create "${BM_PORT_NAME}" \
  --network "${BAREMETAL_NET_ID}" \
  --fixed-ip "subnet=${BAREMETAL_SUBNET_ID}" \
  --disable-port-security >/dev/null
BM_PORT_ID="$(openstack port show "${BM_PORT_NAME}" -f value -c id)"
echo "Baremetal port ID: ${BM_PORT_ID}"

echo "=== Boot server ==="
openstack server create "${SERVER_NAME}" \
  --flavor "${WRK01_FLAVOR_NAME}" \
  --volume "${BOOT_VOL_NAME}" \
  --nic "port-id=${BM_PORT_ID}" \
  --key-name "${OS_KEYPAIR}" \
  --user-data "${USER_DATA_FILE}" \
  --tag "env=${ENVIRONMENT}" \
  --tag "hyperscaler=${HYPERSCALER_TAG}" >/dev/null

echo "Waiting (up to ${WAIT_SEC_SERVER}s) for server to become 'ACTIVE'..."
wait_for_status "openstack server show ${SERVER_NAME} -f value -c status" "ACTIVE" "${WAIT_SEC_SERVER}" \
  || die "Server did not reach ACTIVE in time."

echo "=== Success ==="
openstack server show "${SERVER_NAME}"
openstack port show "${BM_PORT_ID}"
openstack volume show "${BOOT_VOL_NAME}"
echo "Log file: ${LOG_FILE}"
how to run

source env + set keypair (if not already set)

bash
Copy
Edit
source ~/openrc   # or your admin env
export OS_KEYPAIR=your_keypair_name
# optional toggles:
export DEBUG=1              # to see every command (bash -x)
export CLEANUP_ON_FAIL=1    # to auto-delete partial resources on error
execute

bash
Copy
Edit
chmod +x deploy_baremetal_wrk01.sh
./deploy_baremetal_wrk01.sh
grab logs
All output is saved to a timestamped log file like deploy_to01-wrk01-vm_YYYYMMDD-HHMMSS.log.

quick debug playbook (what the script already does, and how to read it)

pre-flight checks fail (flavor/image/network/subnet/keypair not found)

fix the wrong ID/name (most common: image UUID or wrong region).

re-run.

volume stuck not “available”

check: openstack volume show <name> status and openstack volume set --read-only False <id> if locked.

ensure the Glance image is healthy and the Cinder backend has capacity.

port create fails

confirm network/subnet IDs belong to the same project/region.

baremetal networks often require port‑security disabled (we do that). If your cloud enforces RBAC, ensure your role allows it.

server stuck in BUILD or goes to ERROR

script prints: openstack server show, events, and last 200 lines of console log.

common causes:

wrong baremetal flavor (doesn’t map to Ironic) → verify with your cloud: openstack flavor show baremetal --fit-width.

scheduling / capacity issues in Ironic → check with ops or openstack baremetal node list.

boot‑from‑volume not permitted for your Ironic profile → try image‑direct boot if required by your cloud.

cloud‑init issues (comes up ACTIVE but not configured)

check inside VM: /var/log/cloud-init.log and /var/log/cloud-init-output.log.

script writes /etc/orchestrator/config.json and /var/log/chef/* (once your bootstrap runs).

rerun after a failure

with CLEANUP_ON_FAIL=1, partial artifacts should be gone.

otherwise, manually delete:

bash
Copy
Edit
openstack server delete to01-wrk01-vm
openstack port delete to01-wrk01-vm-bm-port
openstack volume delete to01-wrk01-vm-root
want me to add a retry wrapper (e.g., retry server build twice before failing), or export these logs to a artifacts folder automatically?











