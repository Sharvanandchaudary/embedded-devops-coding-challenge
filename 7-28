Goal:

To test the Cadence-standard RHEL 8 image and deploy it on bare metal.

To run Packer on the default image and install all required libraries for environment readiness.

Work Done:

Tested the image built using Cadence standards; observed that it faces an MBR issue — although the image contains an EFI partition, it uses an MBR partition table, making it bootable only in BIOS mode and not compatible with UEFI-based bare metal provisioning.

Successfully ran the Packer build process on the image to install required packages and configurations.

Encountered issues in publishing the Packer-built image due to required changes in Terraform files (bucket path and publishing logic).

Identified and resolved issues in the Packer workflow related to AWS Secrets Manager integration and Terraform bucket configuration.

Synced up with Varsha to align on ongoing and pending work related to customer support configurations.

Requested access permissions needed for the Rcurme support tasks as part of the standard image deployment workflow.














working script

#!/bin/bash
set -e

# Existing bootable volume you want to use
VOLUME_ID="20189745-bc77-41ee-ab7e-563a3a1b9895"


  echo "===== Creating GPU VM $i ====="

  # Create a new port for this VM
  port_id=$(openstack port create \
    --network 3eb39e89-ac62-4b5b-a313-8d52482cc1f2 \
    --fixed-ip subnet=e5db0db9-bf93-43f4-928a-e46e099fef9e \
    --enable test-gpu-port-$i -f json | jq -r '.id')
  echo "Created port: $port_id"

  # Apply security groups to the port
  openstack port set \
    --security-group b3455868-8842-4b16-9f35-684e25f25f28 \
    --security-group 1320ddfd-e090-4300-8d9c-c0d10dfaf84b \
    --security-group c741134d-43d3-4419-bb55-ba6e60bead75 \
    --security-group 58269c3b-bd2d-4287-aedc-2e2f2c744c19 \
    $port_id

  # Create and associate a floating IP
  openstack floating ip create -f json \
    --subnet e33be8b2-02e2-41a5-87b5-830ba5d0db7a \
    --port $port_id pro-net-vlan1162 > /dev/null
  echo "Floating IP created for GPU VM $i"

  # Create server using GPU flavor and existing volume
  openstack server create \
    --flavor m8g.xlarge \
    --volume $VOLUME_ID \
    --security-group b3455868-8842-4b16-9f35-684e25f25f28 \
    --security-group 1320ddfd-e090-4300-8d9c-c0d10dfaf84b \
    --security-group c741134d-43d3-4419-bb55-ba6e60bead75 \
    --security-group 58269c3b-bd2d-4287-aedc-2e2f2c744c19 \
    --port $port_id \



554e21bf-8d0c-4afc-a59a-8763b882efa2








#!/bin/bash
set -e

IMAGE_ID="554e21bf-8d0c-4afc-a59a-8763b882efa2"

echo "===== Creating GPU VM $i ====="

# Create port
port_id=$(openstack port create \
  --network 3eb39e89-ac62-4b5b-a313-8d52482cc1f2 \
  --fixed-ip subnet=e5db0db9-bf93-43f4-928a-e46e099fef9e \
  --enable test-gpu-port-$i -f json | jq -r '.id')
echo "Created port: $port_id"

# Set security groups
openstack port set \
  --security-group b3455868-8842-4b16-9f35-684e25f25f28 \
  --security-group 1320ddfd-e090-4300-8d9c-c0d10dfaf84b \
  --security-group c741134d-43d3-4419-bb55-ba6e60bead75 \
  --security-group 58269c3b-bd2d-4287-aedc-2e2f2c744c19 \
  $port_id

# Create and assign floating IP
openstack floating ip create -f json \
  --subnet e33be8b2-02e2-41a5-87b5-830ba5d0db7a \
  --port $port_id pro-net-vlan1162 > /dev/null
echo "Floating IP created for GPU VM $i"

# Create the VM from IMAGE
openstack server create \
  --flavor m8g.xlarge \
  --image $IMAGE_ID \
  --security-group b3455868-8842-4b16-9f35-684e25f25f28 \
  --security-group 1320ddfd-e090-4300-8d9c-c0d10dfaf84b \
  --security-group c741134d-43d3-4419-bb55-ba6e60bead75 \
  --security-group 58269c3b-bd2d-4287-aedc-2e2f2c744c19 \
  --port $port_id \
  --key-name c30-drm-keypair \
  --wait test-gpu-vm

echo "✅ VM created from image $IMAGE_ID"



#!/bin/bash
set -e

IMAGE_ID="554e21bf-8d0c-4afc-a59a-8763b882efa2"
VOLUME_SIZE_GB=400  # Adjust if needed
VM_NAME="test-gpu-vm"
PORT_NAME="test-gpu-port"
FLOATING_NET="pro-net-vlan1162"

echo "===== Creating GPU VM ====="

# Step 1: Create port
port_id=$(openstack port create \
  --network 3eb39e89-ac62-4b5b-a313-8d52482cc1f2 \
  --fixed-ip subnet=e5db0db9-bf93-43f4-928a-e46e099fef9e \
  --enable ${PORT_NAME} -f json | jq -r '.id')
echo "Created port: $port_id"

# Step 2: Set security groups
openstack port set \
  --security-group b3455868-8842-4b16-9f35-684e25f25f28 \
  --security-group 1320ddfd-e090-4300-8d9c-c0d10dfaf84b \
  --security-group c741134d-43d3-4419-bb55-ba6e60bead75 \
  --security-group 58269c3b-bd2d-4287-aedc-2e2f2c744c19 \
  "$port_id"

# Step 3: Create and assign floating IP
openstack floating ip create -f json \
  --subnet e33be8b2-02e2-41a5-87b5-830ba5d0db7a \
  --port "$port_id" "$FLOATING_NET" > /dev/null
echo "Floating IP created for GPU VM"

# Step 4: Create bootable volume from image
volume_id=$(openstack volume create \
  --image "$IMAGE_ID" \
  --size "$VOLUME_SIZE_GB" \
  --bootable "${VM_NAME}-boot-vol" -f json | jq -r '.id')
echo "Created bootable volume: $volume_id"

# Step 5: Wait for volume to become available
while true; do
  status=$(openstack volume show "$volume_id" -f value -c status)
  if [ "$status" = "available" ]; then
    break
  else
    echo "Waiting for volume $volume_id to become available... status: $status"
    sleep 5
  fi
done

# Step 6: Create the VM from the bootable volume
openstack server create \
  --flavor m8g.xlarge \
  --volume "$volume_id" \
  --port "$port_id" \
  --key-name c30-drm-keypair \
  --wait "$VM_NAME" \
  --security-group b3455868-8842-4b16-9f35-684e25f25f28 \
  --security-group 1320ddfd-e090-4300-8d9c-c0d10dfaf84b \
  --security-group c741134d-43d3-4419-bb55-ba6e60bead75 \
  --security-group 58269c3b-bd2d-4287-aedc-2e2f2c744c19

echo "✅ VM '$VM_NAME' created successfully from image $IMAGE_ID"





✅ 1. Update the System
bash
Copy
Edit
sudo apt update && sudo apt upgrade -y
✅ 2. Add NVIDIA's Package Repositories
bash
Copy
Edit
sudo apt install -y wget software-properties-common gnupg
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600

# Replace with the latest key if this changes
sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/3bf863cc.pub

sudo add-apt-repository "deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /"
sudo apt update
💡 If you're using Ubuntu 22.04, replace ubuntu2004 with ubuntu2204 in the above URLs.

✅ 3. Install NVIDIA Driver + CUDA Toolkit
bash
Copy
Edit
sudo apt install -y cuda-drivers cuda-toolkit-11-8
This will install:

nvidia-smi

nvcc (CUDA compiler)

Kernel modules

✅ 4. Reboot the VM
bash
Copy
Edit
sudo reboot
Then SSH back in:

bash
Copy
Edit
ssh -i your-key.pem ubuntu@<floating-ip>
✅ 5. Check That GPU is Detected
🔹 Is the GPU recognized?
bash
Copy
Edit
nvidia-smi
Expected output: something like this 👇

lua
Copy
Edit
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 535.54.03    Driver Version: 535.54.03    CUDA Version: 12.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
|  0  NVIDIA A100-PCIE...  Off  | 00000000:00:1E.0 Off |                    0 |
+-------------------------------+----------------------+----------------------+
🔹 If nvidia-smi not found:
bash
Copy
Edit
which nvidia-smi
dpkg -l | grep nvidia
✅ 6. Confirm GPU is Attached
bash
Copy
Edit
lspci | grep -i nvidia
Expected output:

makefile
Copy
Edit
00:1e.0 VGA compatible controller: NVIDIA Corporation GPU Model...
✅ 7. Test GPU with CUDA Sample
bash
Copy
Edit
# Install build tools
sudo apt install -y build-essential

# Download CUDA samples
cuda-install-samples-11.8.sh ~
cd ~/NVIDIA_CUDA-11.8_Samples/1_Utilities/deviceQuery

# Compile and run
make
./deviceQuery
Expected output should end with:

ini
Copy
Edit
Result = PASS
✅ Optional: Run TensorFlow or PyTorch GPU Test
🔹 Install Python environment
bash
Copy
Edit
sudo apt install -y python3-pip
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118
🔹 Python GPU test
python
Copy
Edit
python3 -c "import torch; print(torch.cuda.is_available()); print(torch.cuda.get_device_name(0))"
Expected:

graphql
Copy
Edit
True
NVIDIA A100-PCIE-40GB
✅ Summary of Key Commands
Purpose	Command
Install drivers	sudo apt install cuda-drivers
Check GPU status	nvidia-smi
Detect hardware	`lspci
Run CUDA test	./deviceQuery
Verify with PyTorch	Python torch.cuda.is_available()




















📦 Step 1: Update System and Install Dependencies
bash
Copy
Edit
dnf update -y
dnf install -y gcc kernel-devel kernel-headers dkms make elfutils-libelf libglvnd-glx libglvnd-opengl libglvnd-devel libglvnd
Also install EPEL (if needed):

bash
Copy
Edit
dnf install -y epel-release
💡 Step 2: Disable Nouveau Driver (Required)
bash
Copy
Edit
cat <<EOF > /etc/modprobe.d/disable-nouveau.conf
blacklist nouveau
options nouveau modeset=0
EOF

dracut --force
Then reboot:

bash
Copy
Edit
reboot
After reboot, confirm nouveau is disabled:

bash
Copy
Edit
lsmod | grep nouveau   # should return nothing
🚀 Step 3: Download & Install NVIDIA Driver (Official .run method)
Get the latest .run file from:
👉 https://www.nvidia.com/Download/index.aspx

Or directly (example for RHEL 8/9-compatible version):

bash
Copy
Edit
wget https://us.download.nvidia.com/XFree86/Linux-x86_64/535.154.05/NVIDIA-Linux-x86_64-535.154.05.run
chmod +x NVIDIA-Linux-x86_64-535.154.05.run
Switch to multi-user mode (disable GUI if running):

bash
Copy
Edit
systemctl isolate multi-user.target
Run the installer:

bash
Copy
Edit
./NVIDIA-Linux-x86_64-535.154.05.run
Accept the license

Say Yes to DKMS if prompted

Say No to installing 32-bit libs (unless you need them)

✅ Step 4: Verify GPU Installation
After reboot:

bash
Copy
Edit
nvidia-smi
Expected output:

diff
Copy
Edit
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 535.154.05   Driver Version: 535.154.05   CUDA Version: 12.2    |
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile ECC |
|  0  NVIDIA A100-PCIE...        | ...                 |       0      |
+-----------------------------------------------------------------------------+
🧪 Step 5 (Optional): Run a CUDA Test
bash
Copy
Edit
dnf install -y git
git clone https://github.com/NVIDIA/cuda-samples.git
cd cuda-samples/Samples/1_Utilities/deviceQuery
make
./deviceQuery
It should end with:

ini
Copy
Edit
Result = PASS
🔍 Final Notes
Task	Status
Disable Nouveau driver	✅ Required
Install kernel headers	✅ Required for DKMS
Run .run installer	✅ Cleanest on RHEL
Reboot	✅ Required after driver install
Test GPU with nvidia-smi	✅ Confirms success

Let me know if you want to:

Install the full CUDA toolkit

Set up GPU support for PyTorch or TensorFlow

Automate this with a script

You're very close — great work!





#!/bin/bash
set -e

# Bootable volume ID you provided
VOLUME_ID="554e21bf-8d0c-4afc-a59a-8763b882efa2"

# Variables from Terraform
NETWORK_ID="23f15701-a72f-4d9c-8f2f-de8a470e1514"
FLOATING_IP_ID="77d4ae8b-9792-495c-bb7b-aaa5569da518"
SEC_GROUP="dfcded29-7ee4-4f19-bb35-30773d62a2f4"
VM_NAME="auto-vm-01"
FLAVOR="m8g.xlarge"

echo "Creating port..."
PORT_ID=$(openstack port create \
  --network "$NETWORK_ID" \
  --enable "${VM_NAME}-port" \
  --security-group "$SEC_GROUP" \
  -f json | jq -r '.id')

echo "Assigning floating IP to port..."
openstack floating ip set --port "$PORT_ID" "$FLOATING_IP_ID"

echo "Creating instance..."
openstack server create \
  --flavor "$FLAVOR" \
  --volume "$VOLUME_ID" \
  --port "$PORT_ID" \
  --wait \
  "$VM_NAME"

echo "✅ Instance $VM_NAME created and floating IP is bound."

network : 23f15701-a72f-4d9c-8f2f-de8a470e1514
flaoting ip 77d4ae8b-9792-495c-bb7b-aaa5569da518
Image id: 705495d2-f0c6-44fa-aabd-90577d989fcc
sg list "dfcded29-7ee4-4f19-bb35-30773d62a2f4
m1.large




image 705495d2-f0c6-44fa-aabd-90577d989fcc
Dn01 packer
Network  23f15701-a72f-4d9c-8f2f-de8a470e1514
subnet 81952139-370a-464f-8940-62d6ef967
pro-subnet-1132 

security groups

80a223b3-273f-44c3-b22c-7c90e9259b3b

866eaf2b-fc80-496a-a440-f0e6cfc310f0

1db5e212-a003-4557-9898-d649b475269a

32d5b9f5-a613-4853-b326-588b47c37fe2






#!/bin/bash
set -e

# === Parameters ===
IMAGE_ID="705495d2-f0c6-44fa-aabd-90577d989fcc"
VM_NAME="dn01-packer"
FLAVOR="m8g.xlarge"

# Network and Subnet
NETWORK_ID="23f15701-a72f-4d9c-8f2f-de8a470e1514"
SUBNET_ID="81952139-370a-464f-8940-62d6ef967"

# Security Groups
SEC_GROUPS=(
  80a223b3-273f-44c3-b22c-7c90e9259b3b
  866eaf2b-fc80-496a-a440-f0e6cfc310f0
  1db5e212-a003-4557-9898-d649b475269a
  32d5b9f5-a613-4853-b326-588b47c37fe2
)

# Optional: You can create a new floating IP or assign an existing one
# To create a new one, uncomment below and update FLOATING_NET
# FLOATING_NET="pro-net-vlan1162"
# FLOATING_IP=$(openstack floating ip create --subnet $SUBNET_ID $FLOATING_NET -f json | jq -r '.floating_ip_address')

# Create a port with fixed IP on the specified subnet
echo "Creating port for $VM_NAME..."
PORT_ID=$(openstack port create \
  --network "$NETWORK_ID" \
  --fixed-ip subnet="$SUBNET_ID" \
  --enable "${VM_NAME}-port" \
  -f json | jq -r '.id')

# Attach security groups to the port
echo "Attaching security groups..."
for sg in "${SEC_GROUPS[@]}"; do
  openstack port set --security-group "$sg" "$PORT_ID"
done

# Create instance using image
echo "Creating server $VM_NAME..."
openstack server create \
  --flavor "$FLAVOR" \
  --image "$IMAGE_ID" \
  --port "$PORT_ID" \
  --wait \
  "$VM_NAME"

echo "✅ VM '$VM_NAME' created successfully and connected to subnet $SUBNET_ID"

 openstack subnet list | grep 8195
| 81952139-370a-464f-8940-62d6ef9671f1 | c30-dn-dev-dn-01-ComputeSubnet2a   | 23f15701-a72f-4d9c-8f2f-de8a470e1514 | 10.154.130.0/24   |
vsaravan@sjcvl-ghrunner1:~$

#!/bin/bash
set -e

# === Parameters ===
IMAGE_ID="705495d2-f0c6-44fa-aabd-90577d989fcc"
VM_NAME="dn01-packer"
FLAVOR="m8g.xlarge"

# Network and Subnet
NETWORK_ID="23f15701-a72f-4d9c-8f2f-de8a470e1514"
SUBNET_ID="81952139-370a-464f-8940-62d6ef9671f1"  # Corrected ID

# Security Groups
SEC_GROUPS=(
  80a223b3-273f-44c3-b22c-7c90e9259b3b
  866eaf2b-fc80-496a-a440-f0e6cfc310f0
  1db5e212-a003-4557-9898-d649b475269a
  32d5b9f5-a613-4853-b326-588b47c37fe2
)











Daily Status Report
Date: [Insert Date]
Engineer: [Your Name]

Today's Work:

Investigated GPU passthrough requirements and found it needs to be enabled by the Cloud IaaS team.

Raised a ticket to the Cloud IaaS team with explanation of PCI passthrough requirements.

Accessed the instance after some delay to begin GPU validation.

Observed that the instance has no internet access, blocking NVIDIA driver verification using nvidia-smi.

Filed a request with the Infosec team to whitelist the NVIDIA driver repository URL.

Confirmed that the expected image and GPU testing were not done by Brian.

Restarted setup from scratch using the RHEL 8.6 image from the development environment.

Conducted initial setup and testing on instance with multiple GPUs.

Raised a pull request for GitHub runner integration in the cloudenvstatus CI/CD repository.

Worked on updating the Dockerfile to build the runner container with all required tools and configurations.

Plan for Tomorrow:

Ensure PCI passthrough is enabled and test using a proper GPU flavor.

Provision a GPU instance and verify GPU attachment and driver functionality using nvidia-smi.

Create and validate a reusable image from the tested setup.

Finalize and configure GitHub Actions runner access from the VM.

Start development of the CI/CD workflow for automated GPU validation.

# Create a port with fixed IP on the specified subnet
echo "Creating port for $VM_NAME..."
PORT_ID=$(openstack port create \
  --network "$NETWORK_ID" \
  --fixed-ip subnet="$SUBNET_ID" \
  --enable "${VM_NAME}-port" \
  -f json | jq -r '.id')

# Attach all security groups
echo "Attaching security groups..."
for sg in "${SEC_GROUPS[@]}"; do
  openstack port set --security-group "$sg" "$PORT_ID"
done

# Launch instance
echo "Creating server $VM_NAME..."
openstack server create \
  --flavor "$FLAVOR" \
  --image "$IMAGE_ID" \
  --port "$PORT_ID" \
  --wait \
  "$VM_NAME"

echo "✅ VM '$VM_NAME' created and attached to subnet $SUBNET_ID"







#!/bin/bash
set -e

# === Parameters ===
IMAGE_ID="705495d2-f0c6-44fa-aabd-90577d989fcc"
VM_NAME="dn01-packer"
FLAVOR="r6i.8xlarge"
KEY_NAME="veera-dev"

# Network and Subnet
NETWORK_ID="23f15701-a72f-4d9c-8f2f-de8a470e1514"
SUBNET_ID="81952139-370a-464f-8940-62d6ef967"

# Security Groups
SEC_GROUPS=(
  80a223b3-273f-44c3-b22c-7c90e9259b3b
  866eaf2b-fc80-496a-a440-f0e6cfc310f0
  1db5e212-a003-4557-9898-d649b475269a
  32d5b9f5-a613-4853-b326-588b47c37fe2
)

# Optional: Floating IP creation (commented out)
# FLOATING_NET="pro-net-vlan1162"
# FLOATING_IP=$(openstack floating ip create --subnet $SUBNET_ID $FLOATING_NET -f json | jq -r '.floating_ip_address')

# Create a port with fixed IP on the specified subnet
echo "Creating port for $VM_NAME..."
PORT_ID=$(openstack port create \
  --network "$NETWORK_ID" \
  --fixed-ip subnet="$SUBNET_ID" \
  --enable "${VM_NAME}-port" \
  -f json | jq -r '.id')

# Attach security groups to the port
echo "Attaching security groups..."
for sg in "${SEC_GROUPS[@]}"; do
  openstack port set --security-group "$sg" "$PORT_ID"
done

# Create instance using image and key pair
echo "Creating server $VM_NAME with key pair $KEY_NAME..."
openstack server create \
  --flavor "$FLAVOR" \
  --image "$IMAGE_ID" \
  --port "$PORT_ID" \
  --key-name "$KEY_NAME" \
  --wait \
  "$VM_NAME"

echo "✅ VM '$VM_NAME' created successfully and connected to subnet $SUBNET_ID with key pair $KEY_NAME"

