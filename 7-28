working script

#!/bin/bash
set -e

# Existing bootable volume you want to use
VOLUME_ID="20189745-bc77-41ee-ab7e-563a3a1b9895"


  echo "===== Creating GPU VM $i ====="

  # Create a new port for this VM
  port_id=$(openstack port create \
    --network 3eb39e89-ac62-4b5b-a313-8d52482cc1f2 \
    --fixed-ip subnet=e5db0db9-bf93-43f4-928a-e46e099fef9e \
    --enable test-gpu-port-$i -f json | jq -r '.id')
  echo "Created port: $port_id"

  # Apply security groups to the port
  openstack port set \
    --security-group b3455868-8842-4b16-9f35-684e25f25f28 \
    --security-group 1320ddfd-e090-4300-8d9c-c0d10dfaf84b \
    --security-group c741134d-43d3-4419-bb55-ba6e60bead75 \
    --security-group 58269c3b-bd2d-4287-aedc-2e2f2c744c19 \
    $port_id

  # Create and associate a floating IP
  openstack floating ip create -f json \
    --subnet e33be8b2-02e2-41a5-87b5-830ba5d0db7a \
    --port $port_id pro-net-vlan1162 > /dev/null
  echo "Floating IP created for GPU VM $i"

  # Create server using GPU flavor and existing volume
  openstack server create \
    --flavor m8g.xlarge \
    --volume $VOLUME_ID \
    --security-group b3455868-8842-4b16-9f35-684e25f25f28 \
    --security-group 1320ddfd-e090-4300-8d9c-c0d10dfaf84b \
    --security-group c741134d-43d3-4419-bb55-ba6e60bead75 \
    --security-group 58269c3b-bd2d-4287-aedc-2e2f2c744c19 \
    --port $port_id \



554e21bf-8d0c-4afc-a59a-8763b882efa2








#!/bin/bash
set -e

IMAGE_ID="554e21bf-8d0c-4afc-a59a-8763b882efa2"

echo "===== Creating GPU VM $i ====="

# Create port
port_id=$(openstack port create \
  --network 3eb39e89-ac62-4b5b-a313-8d52482cc1f2 \
  --fixed-ip subnet=e5db0db9-bf93-43f4-928a-e46e099fef9e \
  --enable test-gpu-port-$i -f json | jq -r '.id')
echo "Created port: $port_id"

# Set security groups
openstack port set \
  --security-group b3455868-8842-4b16-9f35-684e25f25f28 \
  --security-group 1320ddfd-e090-4300-8d9c-c0d10dfaf84b \
  --security-group c741134d-43d3-4419-bb55-ba6e60bead75 \
  --security-group 58269c3b-bd2d-4287-aedc-2e2f2c744c19 \
  $port_id

# Create and assign floating IP
openstack floating ip create -f json \
  --subnet e33be8b2-02e2-41a5-87b5-830ba5d0db7a \
  --port $port_id pro-net-vlan1162 > /dev/null
echo "Floating IP created for GPU VM $i"

# Create the VM from IMAGE
openstack server create \
  --flavor m8g.xlarge \
  --image $IMAGE_ID \
  --security-group b3455868-8842-4b16-9f35-684e25f25f28 \
  --security-group 1320ddfd-e090-4300-8d9c-c0d10dfaf84b \
  --security-group c741134d-43d3-4419-bb55-ba6e60bead75 \
  --security-group 58269c3b-bd2d-4287-aedc-2e2f2c744c19 \
  --port $port_id \
  --key-name c30-drm-keypair \
  --wait test-gpu-vm

echo "‚úÖ VM created from image $IMAGE_ID"



#!/bin/bash
set -e

IMAGE_ID="554e21bf-8d0c-4afc-a59a-8763b882efa2"
VOLUME_SIZE_GB=400  # Adjust if needed
VM_NAME="test-gpu-vm"
PORT_NAME="test-gpu-port"
FLOATING_NET="pro-net-vlan1162"

echo "===== Creating GPU VM ====="

# Step 1: Create port
port_id=$(openstack port create \
  --network 3eb39e89-ac62-4b5b-a313-8d52482cc1f2 \
  --fixed-ip subnet=e5db0db9-bf93-43f4-928a-e46e099fef9e \
  --enable ${PORT_NAME} -f json | jq -r '.id')
echo "Created port: $port_id"

# Step 2: Set security groups
openstack port set \
  --security-group b3455868-8842-4b16-9f35-684e25f25f28 \
  --security-group 1320ddfd-e090-4300-8d9c-c0d10dfaf84b \
  --security-group c741134d-43d3-4419-bb55-ba6e60bead75 \
  --security-group 58269c3b-bd2d-4287-aedc-2e2f2c744c19 \
  "$port_id"

# Step 3: Create and assign floating IP
openstack floating ip create -f json \
  --subnet e33be8b2-02e2-41a5-87b5-830ba5d0db7a \
  --port "$port_id" "$FLOATING_NET" > /dev/null
echo "Floating IP created for GPU VM"

# Step 4: Create bootable volume from image
volume_id=$(openstack volume create \
  --image "$IMAGE_ID" \
  --size "$VOLUME_SIZE_GB" \
  --bootable "${VM_NAME}-boot-vol" -f json | jq -r '.id')
echo "Created bootable volume: $volume_id"

# Step 5: Wait for volume to become available
while true; do
  status=$(openstack volume show "$volume_id" -f value -c status)
  if [ "$status" = "available" ]; then
    break
  else
    echo "Waiting for volume $volume_id to become available... status: $status"
    sleep 5
  fi
done

# Step 6: Create the VM from the bootable volume
openstack server create \
  --flavor m8g.xlarge \
  --volume "$volume_id" \
  --port "$port_id" \
  --key-name c30-drm-keypair \
  --wait "$VM_NAME" \
  --security-group b3455868-8842-4b16-9f35-684e25f25f28 \
  --security-group 1320ddfd-e090-4300-8d9c-c0d10dfaf84b \
  --security-group c741134d-43d3-4419-bb55-ba6e60bead75 \
  --security-group 58269c3b-bd2d-4287-aedc-2e2f2c744c19

echo "‚úÖ VM '$VM_NAME' created successfully from image $IMAGE_ID"





‚úÖ 1. Update the System
bash
Copy
Edit
sudo apt update && sudo apt upgrade -y
‚úÖ 2. Add NVIDIA's Package Repositories
bash
Copy
Edit
sudo apt install -y wget software-properties-common gnupg
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600

# Replace with the latest key if this changes
sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/3bf863cc.pub

sudo add-apt-repository "deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /"
sudo apt update
üí° If you're using Ubuntu 22.04, replace ubuntu2004 with ubuntu2204 in the above URLs.

‚úÖ 3. Install NVIDIA Driver + CUDA Toolkit
bash
Copy
Edit
sudo apt install -y cuda-drivers cuda-toolkit-11-8
This will install:

nvidia-smi

nvcc (CUDA compiler)

Kernel modules

‚úÖ 4. Reboot the VM
bash
Copy
Edit
sudo reboot
Then SSH back in:

bash
Copy
Edit
ssh -i your-key.pem ubuntu@<floating-ip>
‚úÖ 5. Check That GPU is Detected
üîπ Is the GPU recognized?
bash
Copy
Edit
nvidia-smi
Expected output: something like this üëá

lua
Copy
Edit
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 535.54.03    Driver Version: 535.54.03    CUDA Version: 12.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
|  0  NVIDIA A100-PCIE...  Off  | 00000000:00:1E.0 Off |                    0 |
+-------------------------------+----------------------+----------------------+
üîπ If nvidia-smi not found:
bash
Copy
Edit
which nvidia-smi
dpkg -l | grep nvidia
‚úÖ 6. Confirm GPU is Attached
bash
Copy
Edit
lspci | grep -i nvidia
Expected output:

makefile
Copy
Edit
00:1e.0 VGA compatible controller: NVIDIA Corporation GPU Model...
‚úÖ 7. Test GPU with CUDA Sample
bash
Copy
Edit
# Install build tools
sudo apt install -y build-essential

# Download CUDA samples
cuda-install-samples-11.8.sh ~
cd ~/NVIDIA_CUDA-11.8_Samples/1_Utilities/deviceQuery

# Compile and run
make
./deviceQuery
Expected output should end with:

ini
Copy
Edit
Result = PASS
‚úÖ Optional: Run TensorFlow or PyTorch GPU Test
üîπ Install Python environment
bash
Copy
Edit
sudo apt install -y python3-pip
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118
üîπ Python GPU test
python
Copy
Edit
python3 -c "import torch; print(torch.cuda.is_available()); print(torch.cuda.get_device_name(0))"
Expected:

graphql
Copy
Edit
True
NVIDIA A100-PCIE-40GB
‚úÖ Summary of Key Commands
Purpose	Command
Install drivers	sudo apt install cuda-drivers
Check GPU status	nvidia-smi
Detect hardware	`lspci
Run CUDA test	./deviceQuery
Verify with PyTorch	Python torch.cuda.is_available()




















üì¶ Step 1: Update System and Install Dependencies
bash
Copy
Edit
dnf update -y
dnf install -y gcc kernel-devel kernel-headers dkms make elfutils-libelf libglvnd-glx libglvnd-opengl libglvnd-devel libglvnd
Also install EPEL (if needed):

bash
Copy
Edit
dnf install -y epel-release
üí° Step 2: Disable Nouveau Driver (Required)
bash
Copy
Edit
cat <<EOF > /etc/modprobe.d/disable-nouveau.conf
blacklist nouveau
options nouveau modeset=0
EOF

dracut --force
Then reboot:

bash
Copy
Edit
reboot
After reboot, confirm nouveau is disabled:

bash
Copy
Edit
lsmod | grep nouveau   # should return nothing
üöÄ Step 3: Download & Install NVIDIA Driver (Official .run method)
Get the latest .run file from:
üëâ https://www.nvidia.com/Download/index.aspx

Or directly (example for RHEL 8/9-compatible version):

bash
Copy
Edit
wget https://us.download.nvidia.com/XFree86/Linux-x86_64/535.154.05/NVIDIA-Linux-x86_64-535.154.05.run
chmod +x NVIDIA-Linux-x86_64-535.154.05.run
Switch to multi-user mode (disable GUI if running):

bash
Copy
Edit
systemctl isolate multi-user.target
Run the installer:

bash
Copy
Edit
./NVIDIA-Linux-x86_64-535.154.05.run
Accept the license

Say Yes to DKMS if prompted

Say No to installing 32-bit libs (unless you need them)

‚úÖ Step 4: Verify GPU Installation
After reboot:

bash
Copy
Edit
nvidia-smi
Expected output:

diff
Copy
Edit
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 535.154.05   Driver Version: 535.154.05   CUDA Version: 12.2    |
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile ECC |
|  0  NVIDIA A100-PCIE...        | ...                 |       0      |
+-----------------------------------------------------------------------------+
üß™ Step 5 (Optional): Run a CUDA Test
bash
Copy
Edit
dnf install -y git
git clone https://github.com/NVIDIA/cuda-samples.git
cd cuda-samples/Samples/1_Utilities/deviceQuery
make
./deviceQuery
It should end with:

ini
Copy
Edit
Result = PASS
üîç Final Notes
Task	Status
Disable Nouveau driver	‚úÖ Required
Install kernel headers	‚úÖ Required for DKMS
Run .run installer	‚úÖ Cleanest on RHEL
Reboot	‚úÖ Required after driver install
Test GPU with nvidia-smi	‚úÖ Confirms success

Let me know if you want to:

Install the full CUDA toolkit

Set up GPU support for PyTorch or TensorFlow

Automate this with a script

You're very close ‚Äî great work!





#!/bin/bash
set -e

# Bootable volume ID you provided
VOLUME_ID="554e21bf-8d0c-4afc-a59a-8763b882efa2"

# Variables from Terraform
NETWORK_ID="23f15701-a72f-4d9c-8f2f-de8a470e1514"
FLOATING_IP_ID="77d4ae8b-9792-495c-bb7b-aaa5569da518"
SEC_GROUP="dfcded29-7ee4-4f19-bb35-30773d62a2f4"
VM_NAME="auto-vm-01"
FLAVOR="m8g.xlarge"

echo "Creating port..."
PORT_ID=$(openstack port create \
  --network "$NETWORK_ID" \
  --enable "${VM_NAME}-port" \
  --security-group "$SEC_GROUP" \
  -f json | jq -r '.id')

echo "Assigning floating IP to port..."
openstack floating ip set --port "$PORT_ID" "$FLOATING_IP_ID"

echo "Creating instance..."
openstack server create \
  --flavor "$FLAVOR" \
  --volume "$VOLUME_ID" \
  --port "$PORT_ID" \
  --wait \
  "$VM_NAME"

echo "‚úÖ Instance $VM_NAME created and floating IP is bound."






