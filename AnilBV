vsaravan@sjcvl-ghrunner1:~$ ./create_bm_network.sh
Keypair 'c30-to-test-to-01-wrk01-keypair' exists.
Creating provisioning port on PXE MAC c4:cb:e1:dd:19:6e ...
binding_host_id: ''
data_plane_status: null
device_id: ''
  hostname: host-10-107-177-60
dns_name: ''
fixed_ips:
  subnet_id: c83e54b1-822e-4931-ac73-b731d1f6c966
id: 553a0e55-299d-407b-9c37-400627fb6247
mac_address: c4:cb:e1:dd:19:6e
name: to01-wrk01-vm-prov
network_id: 5c79a1a8-b294-4435-a2e6-ef1b992735d3
project_id: 59c2d928ef6046069a0175d74dc3dc23
propagate_uplink_status: null
qos_network_policy_id: null
qos_policy_id: null
status: DOWN
Creating chamber port on MAC 6c:92:cf:27:ce:50 with fixed IP 10.154.180.52 ...
ConflictException: 409: Client Error for url: https://test.openstack.cadence.com:13696/v2.0/ports, IP address 10.154.180.52 already allocated in subnet f09dc8d8-5b9e-4ed2-9ea6-10cbfb3130ec
---- FAIL (rc=1). Last 80 log lines ----
Keypair 'c30-to-test-to-01-wrk01-keypair' exists.
Creating provisioning port on PXE MAC c4:cb:e1:dd:19:6e ...
binding_host_id: ''
data_plane_status: null
device_id: ''
  hostname: host-10-107-177-60
dns_name: ''
fixed_ips:
  subnet_id: c83e54b1-822e-4931-ac73-b731d1f6c966
id: 553a0e55-299d-407b-9c37-400627fb6247
mac_address: c4:cb:e1:dd:19:6e
name: to01-wrk01-vm-prov
network_id: 5c79a1a8-b294-4435-a2e6-ef1b992735d3
project_id: 59c2d928ef6046069a0175d74dc3dc23
propagate_uplink_status: null
qos_network_policy_id: null
qos_policy_id: null
status: DOWN
Creating chamber port on MAC 6c:92:cf:27:ce:50 with fixed IP 10.154.180.52 ...
ConflictException: 409: Client Error for url: https://test.openstack.cadence.com:13696/v2.0/ports, IP address 10.154.180.52 already allocated in subnet f09dc8d8-5b9e-4ed2-9ea6-10cbfb3130ec
---- FAIL (rc=1). Last 80 log lines ----
--- cleanup starting ---
Deleting port 553a0e55-299d-407b-9c37-400627fb6247 ...
--- cleanup done ---


























+------------------+-------------------------------------------------------------------------------------------------------+
vsaravan@sjcvl-ghrunner1:~$ openstack image show f3f9d14d-f741-4a98-b8fb-c142d1334e97
+------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Field            | Value                                                                                                                                                                                      |
+------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| checksum         | 5f4771c2cfbc52eebc3c5df20e994a7d                                                                                                                                                           |
| container_format | bare                                                                                                                                                                                       |
| created_at       | 2025-08-14T09:45:39Z                                                                                                                                                                       |
| disk_format      | qcow2                                                                                                                                                                                      |
| file             | /v2/images/f3f9d14d-f741-4a98-b8fb-c142d1334e97/file                                                                                                                                       |
| id               | f3f9d14d-f741-4a98-b8fb-c142d1334e97                                                                                                                                                       |
| min_disk         | 0                                                                                                                                                                                          |
| min_ram          | 0                                                                                                                                                                                          |
| name             | rhel8.6-auth-export                                                                                                                                                                        |
| owner            | dcfb102e7fc940c39c0c21c48d77d3cf                                                                                                                                                           |
| properties       | os_hash_algo='sha512', os_hash_value='18dd076f6ba4202cd8468554d60b62fe69932f0684a12fc0996ef1500a005ad0d8698280326555726697ea4a8335f15d7c218f1c2fbc25221b0567ae413d2229',                   |
|                  | os_hidden='False', stores='default_backend'                                                                                                                                                |
| protected        | False                                                                                                                                                                                      |
| schema           | /v2/schemas/image                                                                                                                                                                          |
| size             | 5294718976                                                                                                                                                                                 |
| status           | active                                                                                                                                                                                     |
| tags             |                                                                                                                                                                                            |
| updated_at       | 2025-08-14T09:52:38Z                                                                                                                                                                       |
| virtual_size     | 107374182400                                                                                                                                                                               |
| visibility       | shared                                                                                                                                                                                     |
+------------------+---------------










vsaravan@sjcvl-ghrunner1:~$ openstack image show  bda2d284-54f7-4aef-bc21-4c85a3e52083
+------------------+-------------------------------------------------------------------------------------------------------+
| Field            | Value                                                                                                 |
+------------------+-------------------------------------------------------------------------------------------------------+
| checksum         | d41d8cd98f00b204e9800998ecf8427e                                                                      |
| container_format | bare                                                                                                  |
| created_at       | 2025-08-14T08:48:17Z                                                                                  |
| disk_format      | qcow2                                                                                                 |
| file             | /v2/images/bda2d284-54f7-4aef-bc21-4c85a3e52083/file                                                  |
| id               | bda2d284-54f7-4aef-bc21-4c85a3e52083                                                                  |
| min_disk         | 100                                                                                                   |
| min_ram          | 0                                                                                                     |
| name             | rhel8.6cdns-snap-auth                                                                                 |
| owner            | dcfb102e7fc940c39c0c21c48d77d3cf                                                                      |
| properties       | base_image_ref='', bdm_v2='True', block_device_mapping='[{"image_id": null, "boot_index": 0,          |
|                  | "device_name": "/dev/vda", "destination_type": "volume", "volume_type": null, "device_type": "disk",  |
|                  | "snapshot_id": "5b337b1f-13f8-4dd3-abe2-2d539357557f", "disk_bus": "virtio", "guest_format": null,    |
|                  | "delete_on_termination": false, "no_device": null, "tag": null, "source_type": "snapshot",            |
|                  | "volume_id": null, "volume_size": 100}]', boot_roles='member,swiftoperator,reader',                   |
|                  | hw_cdrom_bus='sata', hw_disk_bus='virtio', hw_input_bus='usb', hw_machine_type='pc-q35-rhel9.0.0',    |
|                  | hw_pointer_model='usbtablet', hw_video_model='virtio', hw_vif_model='virtio', os_hash_algo='sha512',  |
|                  | os_hash_value='cf83e1357eefb8bdf1542850d66d8007d620e4050b5715dc83f4a921d36ce9ce47d0d13c5d85f2b0ff8318 |
|                  | d2877eec2f63b931bd47417a81a538327af927da3e', os_hidden='False', owner_project_name='cc-dev-oa-        |
|                  | chm01-prj', owner_user_name='vsaravan', root_device_name='/dev/vda', stores='default_backend'         |
| protected        | False                                                                                                 |
| schema           | /v2/schemas/image                                                                                     |
| size             | 0                                                                                                     |
| status           | active                                                                                                |
| tags             |                                                                                                       |
| updated_at       | 2025-08-14T08:48:17Z                                                                                  |
| visibility       | private                                                                                               |
+------------------+-------------------------------------------------------------------------------------------------------+
vsaravan@sjcvl-ghrunner1:~$ openstack image list | grep  rhel8.6cd














Keypair 'c30-to-test-to-01-wrk01-keypair' exists.
Creating provisioning port on PXE MAC c4:cb:e1:dd:19:6e ...
binding_host_id: ''
data_plane_status: null
device_id: ''
  hostname: host-10-107-177-54
dns_name: ''
fixed_ips:
  subnet_id: c83e54b1-822e-4931-ac73-b731d1f6c966
id: df2a4489-defc-463b-9de9-b13af7465560
mac_address: c4:cb:e1:dd:19:6e
name: to01-wrk01-vm-prov
network_id: 5c79a1a8-b294-4435-a2e6-ef1b992735d3
project_id: 59c2d928ef6046069a0175d74dc3dc23
propagate_uplink_status: null
qos_network_policy_id: null
qos_policy_id: null
status: DOWN
Creating chamber port on MAC 6c:92:cf:27:ce:50 with fixed IP 10.154.180.52 ...
binding_host_id: ''
data_plane_status: null
device_id: ''
  hostname: host-10-154-180-52
dns_name: ''
fixed_ips:
  subnet_id: f09dc8d8-5b9e-4ed2-9ea6-10cbfb3130ec
id: 8c8c72f4-0431-422a-8d87-b118f7507dbf
mac_address: 6c:92:cf:27:ce:50
name: to01-wrk01-vm-data
network_id: 8d28eca5-da32-485f-98c5-d26abaf86d54
project_id: 59c2d928ef6046069a0175d74dc3dc23
propagate_uplink_status: null
qos_network_policy_id: null
qos_policy_id: null
status: DOWN
Booting baremetal server to01-wrk01-vm from image with provisioning + chamber NICs ...
SERVER_ID=b4086ef9-f37f-4159-94fd-7a01eec1aabd
Waiting for server ACTIVE...
Server is ACTIVE.
OS-EXT-SRV-ATTR:hostname: to01-wrk01-vm
OS-EXT-SRV-ATTR:hypervisor_hostname: 16dec879-ba80-4cac-8486-59318d688037
OS-EXT-SRV-ATTR:instance_name: instance-00001336
OS-EXT-SRV-ATTR:kernel_id: ''
OS-EXT-SRV-ATTR:ramdisk_id: ''
OS-EXT-SRV-ATTR:reservation_id: r-1320z1np
OS-EXT-SRV-ATTR:root_device_name: /dev/sda
addresses:
  id: baremetal
  name: baremetal
  original_name: baremetal
hostId: 838d26b583f6d97a72823ef2e65b52d316d166e71eb708222468ff54
host_status: UP
id: b4086ef9-f37f-4159-94fd-7a01eec1aabd
key_name: c30-to-test-to-01-wrk01-keypair
name: to01-wrk01-vm
project_id: 59c2d928ef6046069a0175d74dc3dc23
status: ACTIVE
user_id: 64a837e9a22b4edf90375c7182a9f297
Disabling provisioning port df2a4489-defc-463b-9de9-b13af7465560 ...
Done. Chamber IP should be 10.154.180.52.


this is the log so can we create a script to delete this baremtal ns ports awhat ever reuwired 











want_fixed_ip="10.154.180.52"

if openstack subnet show "$TENANT_SUBNET_ID" -f json | \
   jq -e --arg ip "$want_fixed_ip" '
     .allocation_pools[] 
     | (.start | split(".") | map(tonumber)) as $start
     | (.end | split(".") | map(tonumber)) as $end
     | ($ip | split(".") | map(tonumber)) as $target
     | ($target >= $start and $target <= $end)
   ' >/dev/null; then
  echo "✅ $want_fixed_ip is within the subnet's allocation pool."
else
  echo "❌ $want_fixed_ip is outside the allocation pool — pick another."
fi




# 1) Is that IP already taken?

openstack port list --fixed-ip ip-address=10.154.180.52 -f yaml

# 2) If you get an ID, inspect it:
PORT="<<the ID from above>>"
openstack port show "$PORT" -f yaml | egrep -i 'id:|name:|device_owner:|device_id:|project_id:|mac_address:|network_id:|fixed_ips:'

# 3) Is it a router or DHCP port?
# (these should NOT be deleted)
openstack port show "$PORT" -f value -c device_owner
# expected router types:
#   network:router_interface
#   network:router_gateway
# expected DHCP:
#   network:dhcp
What to do based on the result:

If device_owner is network:router_* or network:dhcp: pick another IP (don’t delete).

If it’s a normal port that you own and don’t need:
openstack port delete "$PORT"

If it belongs to another project (different project_id): choose another IP, or coordinate with that project.

2) One‑liner to find the next free IP in the subnet
Let Neutron pick one for you (safest and fast):

bash
Copy
Edit
# Just omit ip-address to let Neutron assign a free one:
openstack port create my-data-port \
  --network "$TENANT_NET_ID" \
  --fixed-ip "subnet=$TENANT_SUBNET_ID" \
  --mac-address "$DATA_MAC" \
  --vnic-type baremetal \
  --disable-port-security
Then fetch the assigned IP:

bash
Copy
Edit
openstack port show my-data-port -f value -c fixed_ips
3) Make your script robust (won’t fail on taken IP)
Here’s a drop‑in patch that you can put before creating the chamber/data port.
It does this:

If TENANT_IP is set:

If the IP is free ⇒ proceed.

If it exists:

If it’s your port (same MAC & network) ⇒ reuse it.

If it’s a router/DHCP port ⇒ fail with a clear message (choose another IP).

If it’s another normal port you own but wrong MAC ⇒ fail clearly to avoid stealing.

If TENANT_IP is not set ⇒ Neutron auto‑assigns a free one.

bash
Copy
Edit
# ---------- SAFE ALLOCATION FOR CHAMBER PORT ----------
want_fixed_ip="${TENANT_IP:-}"

if [[ -n "$want_fixed_ip" ]]; then
  # Check if the IP is already allocated
  EXISTING_PORT_ID="$(openstack port list --fixed-ip ip-address=$want_fixed_ip -f value -c ID | head -1 || true)"

  if [[ -n "$EXISTING_PORT_ID" ]]; then
    # Inspect the existing port
    EXIST_OWNER="$(openstack port show "$EXISTING_PORT_ID" -f value -c device_owner)"
    EXIST_MAC="$(openstack port show "$EXISTING_PORT_ID" -f value -c mac_address)"
    EXIST_NET="$(openstack port show "$EXISTING_PORT_ID" -f value -c network_id)"

    case "$EXIST_OWNER" in
      network:router_*|network:dhcp)
        die "Requested IP $want_fixed_ip is reserved by $EXIST_OWNER (port $EXISTING_PORT_ID). Pick a different IP."
        ;;
      *)
        if [[ "$EXIST_NET" == "$TENANT_NET_ID" && "$EXIST_MAC" == "$DATA_MAC" ]]; then
          info "Reusing existing data port $EXISTING_PORT_ID at $want_fixed_ip (MAC matches)."
          DATA_PORT_ID="$EXISTING_PORT_ID"
        else
          die "IP $want_fixed_ip already in use by port $EXISTING_PORT_ID (owner=$EXIST_OWNER, mac=$EXIST_MAC, net=$EXIST_NET). Use a different IP or delete the port."
        fi
        ;;
    esac
  else
    # Create a new data port with the requested fixed IP
    DATA_PORT_ID="$(openstack port create "${SERVER_NAME}-data" \
      --network "$TENANT_NET_ID" \
      --fixed-ip "subnet=${TENANT_SUBNET_ID},ip-address=${want_fixed_ip}" \
      --mac-address "$DATA_MAC" \
      --vnic-type baremetal \
      --disable-port-security \
      -f value -c id)"
    CLEAN_DATA="$DATA_PORT_ID"
  fi
else
  # No IP requested, let Neutron assign
  DATA_PORT_ID="$(openstack port create "${SERVER_NAME}-data" \
    --network "$TENANT_NET_ID" \
    --fixed-ip "subnet=${TENANT_SUBNET_ID}" \
    --mac-address "$DATA_MAC" \
    --vnic-type baremetal \
    --disable-port-security \
    -f value -c id)"
  CLEAN_DATA="$DATA_PORT_ID"
  info "Neutron auto-assigned chamber IP:"
  openstack port show "$DATA_PORT_ID" -f value -c fixed_ips
fi
# ---------- END SAFE ALLOCATION ----------
Bonus: if you’d like an auto‑find next free IP inside your allowed range, I can add a tiny helper that lists allocation_pools and walks them until it finds an unused address.

4) TL;DR: How to avoid this forever
Use --plan first in your script to validate the target IP is free.

Or let Neutron auto‑assign by omitting TENANT_IP (least friction).

If you must pin a specific IP, add the exist/reuse logic above so a previous port won’t crash the run.

Never delete router/DHCP ports; just choose a different IP.

If you paste the patch in, I can also send back your full script with the changes in-place. Want me to do that?



























A) Quick debug + fix (run these now)
# --- set your chamber values ---
TENANT_NET_ID="8d28eca5-da32-485f-98c5-d26abaf86d54"
TENANT_SUBNET_ID="f09dc8d8-5b9e-4ed2-9ea6-10cbfb3130ec"
TENANT_IP="10.154.180.52"
DATA_MAC="6c:92:cf:27:ce:50"

# 1) Who owns the IP?
EXISTING_PORT_ID=$(openstack port list --fixed-ip ip-address=$TENANT_IP -f value -c ID | head -1)

if [[ -z "$EXISTING_PORT_ID" ]]; then
  echo "IP $TENANT_IP is free."
else
  echo "IP $TENANT_IP is on port: $EXISTING_PORT_ID"
  openstack port show "$EXISTING_PORT_ID" -f yaml | egrep -i \
    'id:|name:|device_owner:|device_id:|project_id:|network_id:|mac_address:|status:|binding_vnic_type:'
fi


Interpretation & what to do:

device_owner is network:router_* or network:dhcp → Do not touch. Pick another IP.

Else (normal port):

If network_id == $TENANT_NET_ID and mac_address == $DATA_MAC → REUSE this port (good).

If device_id empty (not attached) but MAC different:

safest: delete it (if it’s yours) → openstack port delete $EXISTING_PORT_ID then create a fresh one.

or (if policy allows) update the MAC → openstack port set $EXISTING_PORT_ID --mac-address $DATA_MAC

If it belongs to another project or attached to a live server → choose another IP.

If you’re reusing the port, just record it:

DATA_PORT_ID="$EXISTING_PORT_ID"
openstack port show "$DATA_PORT_ID" -f value -c fixed_ips


Then continue with your normal flow (create provisioning port, boot server using --nic port-id=$DATA_PORT_ID and your provisioning port).













vsaravan@sjcvl-ghrunner1:~$ ./create_bm_network.sh
Keypair 'c30-to-test-to-01-wrk01-keypair' exists.
Creating provisioning port on PXE MAC c4:cb:e1:dd:19:6e ...
binding_host_id: ''
data_plane_status: null
device_id: ''
  hostname: host-10-107-177-75
dns_name: ''
fixed_ips:
  subnet_id: c83e54b1-822e-4931-ac73-b731d1f6c966
id: d5c5a107-9ddb-4062-b95e-f42be01270f4
mac_address: c4:cb:e1:dd:19:6e
name: to01-wrk01-vm-prov
network_id: 5c79a1a8-b294-4435-a2e6-ef1b992735d3
project_id: 59c2d928ef6046069a0175d74dc3dc23
propagate_uplink_status: null
qos_network_policy_id: null
qos_policy_id: null
status: DOWN
Creating chamber port on MAC 6c:92:cf:27:ce:50 with fixed IP 10.154.180.52 ...
ConflictException: 409: Client Error for url: https://test.openstack.cadence.com:13696/v2.0/ports, IP address 10.154.180.52 already allocated in subnet f09dc8d8-5b9e-4ed2-9ea6-10cbfb3130ec
---- FAIL (rc=1). Last 80 log lines ----
Keypair 'c30-to-test-to-01-wrk01-keypair' exists.
Creating provisioning port on PXE MAC c4:cb:e1:dd:19:6e ...
binding_host_id: ''
data_plane_status: null
device_id: ''
  hostname: host-10-107-177-75
dns_name: ''
fixed_ips:
  subnet_id: c83e54b1-822e-4931-ac73-b731d1f6c966
id: d5c5a107-9ddb-4062-b95e-f42be01270f4
mac_address: c4:cb:e1:dd:19:6e
name: to01-wrk01-vm-prov
network_id: 5c79a1a8-b294-4435-a2e6-ef1b992735d3
project_id: 59c2d928ef6046069a0175d74dc3dc23
propagate_uplink_status: null
qos_network_policy_id: null
qos_policy_id: null
status: DOWN
Creating chamber port on MAC 6c:92:cf:27:ce:50 with fixed IP 10.154.180.52 ...
ConflictException: 409: Client Error for url: https://test.openstack.cadence.com:13696/v2.0/ports, IP address 10.154.180.52 already allocated in subnet f09dc8d8-5b9e-4ed2-9ea6-10cbfb3130ec
---- FAIL (rc=1). Last 80 log lines ----
--- cleanup starting ---
Deleting port d5c5a107-9ddb-4062-b95e-f42be01270f4 ...
--- cleanup done ---
vsaravan@sjcvl-ghrunner1:~$































 1db5e212-a003-4557-9898-d649b475269a | c30-dn-dev-dn-01-Platform-SG-sg          | CC Platfom Security Group                              | dcfb102e7fc940c39c0c21c48d77d3cf | ['Backup:none', 'BU:IT', 'BusinessUnit:cloudeng', 'Environment:Non-Production', 'OrganizationName:IT', 'Sub_BU:VCAD', 'Terraform:false', 'todestroy:false', 'tosuspend:false']                      |
| 32d5b9f5-a613-4853-b326-588b47c37fe2 | c30-dn-dev-dn-01-PrivateSG-sg            | Private security group                                 | dcfb102e7fc940c39c0c21c48d77d3cf | ['Backup:none', 'BU:IT', 'BusinessUnit:cloudeng', 'Environment:Non-Production', 'OrganizationName:IT', 'Sub_BU:VCAD', 'Terraform:false', 'todestroy:false', 'tosuspend:false']                      |
| 80a223b3-273f-44c3-b22c-7c90e9259b3b | c30-dn-dev-dn-01-CLA-SG-sg               | Cadence License Agent Security Group                   | dcfb102e7fc940c39c0c21c48d77d3cf | ['Backup:none', 'BU:IT', 'BusinessUnit:cloudeng', 'Environment:Non-Production', 'OrganizationName:IT', 'Sub_BU:VCAD', 'Terraform:false', 'todestroy:false', 'tosuspend:false']                      |
| 866eaf2b-fc80-496a-a440-f0e6cfc310f0 | c30-dn-dev-dn-01-Chm-AccessFromUtlSvr-sg | Utility Server Access from Chamber                     | dcfb102e7fc940c39c0c21c48d77d3cf | ['Backup:none', 'BU:IT', 'BusinessUnit:cloudeng', 'Environment:Non-Production', 'OrganizationName:IT', 'Sub_BU:VCAD', 'Terraform:false', 'todestroy:false', 'tosuspend:false']         

flavor  m1.2xlarge

image 
b1d72102-a72b-4b9a-bca0-de3a36866a1a




aravan@sjcvl-ghrunner1:~$ source /home/srinip/test_os.sh
Please enter your OpenStack Password for project cc-test-oa-chm01-prj as user svc-account-dev-01:
vsaravan@sjcvl-ghrunner1:~$ cat deploy_to01-wrk01-vm_20250813-123330.log
Keypair 'c30-to-test-to-01-wrk01-keypair' exists.
Creating provisioning port on PXE MAC c4:cb:e1:dd:19:6e ...
binding_host_id: ''
data_plane_status: null
device_id: ''
  hostname: host-10-107-177-86
dns_name: ''
fixed_ips:
  subnet_id: c83e54b1-822e-4931-ac73-b731d1f6c966
id: 4b1bedc1-862a-416b-a476-bc87750e2a13
mac_address: c4:cb:e1:dd:19:6e
name: to01-wrk01-vm-prov
network_id: 5c79a1a8-b294-4435-a2e6-ef1b992735d3
project_id: 59c2d928ef6046069a0175d74dc3dc23
propagate_uplink_status: null
qos_network_policy_id: null
qos_policy_id: null
status: DOWN
Creating chamber port on MAC 6c:92:cf:27:ce:50 with fixed IP 10.154.180.52 ...
binding_host_id: ''
data_plane_status: null
device_id: ''
  hostname: host-10-154-180-52
dns_name: ''
fixed_ips:
  subnet_id: f09dc8d8-5b9e-4ed2-9ea6-10cbfb3130ec
id: 999588d0-728d-4b46-ad4f-e0511392562a
mac_address: 6c:92:cf:27:ce:50
name: to01-wrk01-vm-data
network_id: 8d28eca5-da32-485f-98c5-d26abaf86d54
project_id: 59c2d928ef6046069a0175d74dc3dc23
propagate_uplink_status: null
qos_network_policy_id: null
qos_policy_id: null
status: DOWN
Booting baremetal server to01-wrk01-vm from image with provisioning + chamber NICs ...
SERVER_ID=d61a19b1-999b-42f9-b54a-de321a13c57f
Waiting for server ACTIVE...
Server is ACTIVE.
OS-EXT-SRV-ATTR:hostname: to01-wrk01-vm
OS-EXT-SRV-ATTR:hypervisor_hostname: 16dec879-ba80-4cac-8486-59318d688037
OS-EXT-SRV-ATTR:instance_name: instance-00001333
OS-EXT-SRV-ATTR:kernel_id: ''
OS-EXT-SRV-ATTR:ramdisk_id: ''
OS-EXT-SRV-ATTR:reservation_id: r-o9xo7l07
OS-EXT-SRV-ATTR:root_device_name: /dev/sda
addresses:
  id: baremetal
  name: baremetal
  original_name: baremetal
hostId: 838d26b583f6d97a72823ef2e65b52d316d166e71eb708222468ff54
host_status: UP
id: d61a19b1-999b-42f9-b54a-de321a13c57f
key_name: c30-to-test-to-01-wrk01-keypair
name: to01-wrk01-vm
project_id: 59c2d928ef6046069a0175d74dc3dc23
status: ACTIVE
user_id: 64a837e9a22b4edf90375c7182a9f297
Disabling provisioning port 4b1bedc1-862a-416b-a476-bc87750e2a13 ...
Done. Chamber IP should be 10.154.180.52.
Log: ./deploy_to01-wrk01-vm_20250813-123330.log

























#!/usr/bin/env bash
# Auto-cleans on failure. Boots baremetal from image with provisioning + chamber NICs, then disables provisioning NIC.
set -euo pipefail
[[ "${DEBUG:-0}" == "1" ]] && set -x

# ======== Config (your values) ========
HYPERSCALER_TAG="rhops"
ENVIRONMENT="test-2"
NAME_PREFIX="to01"
NODE_NAME="wrk01"
SERVER_NAME="${NAME_PREFIX}-${NODE_NAME}-vm"

# IMAGE / FLAVOR
WRK01_IMAGE_ID="34504ee6-d6ed-4ba7-a366-647bfee3cd49"   # from TF plan (use your working image if preferred)
WRK01_FLAVOR_NAME="baremetal"

# Provisioning (VLAN 1168 path already baked into this net)
PROV_NET_ID="5c79a1a8-b294-4435-a2e6-ef1b992735d3"      # provisioning
PROV_SUBNET_ID="c83e54b1-822e-4931-ac73-b731d1f6c966"   # provisioning-subnet

# Chamber (customer VPC) — fixed IP you asked for
TENANT_NET_ID="8d28eca5-da32-485f-98c5-d26abaf86d54"
TENANT_SUBNET_ID="f09dc8d8-5b9e-4ed2-9ea6-10cbfb3130ec" # 10.154.180.0/23
TENANT_FIXED_IP="10.154.180.52"

# NIC MACs (from your node)
PXE_MAC="c4:cb:e1:dd:19:6e"          # PXE-enabled NIC (provisioning)
DATA_MAC="6c:92:cf:27:ce:50"         # data NIC (chamber)

# Keypair
OS_KEYPAIR="${OS_KEYPAIR:-c30-to-test-to-01-wrk01-keypair}"  # matches TF plan
PUB_KEY_FILE="${PUB_KEY_FILE:-$HOME/.ssh/id_rsa.pub}"

# Timing
WAIT_SEC_SERVER="${WAIT_SEC_SERVER:-1800}"
POLL_INTERVAL="${POLL_INTERVAL:-5}"

# Names
PROV_PORT_NAME="${SERVER_NAME}-prov"
DATA_PORT_NAME="${SERVER_NAME}-data"

# ============ Logging ============
RUN_ID="$(date +%Y%m%d-%H%M%S)"
LOG_FILE="${LOG_FILE:-./deploy_${SERVER_NAME}_${RUN_ID}.log}"
exec > >(tee -a "$LOG_FILE") 2>&1

# ============ State ============
PROV_PORT_ID=""
DATA_PORT_ID=""
SERVER_ID=""

die(){ echo "ERROR: $*" >&2; exit 1; }
need(){ command -v "$1" >/dev/null 2>&1 || die "Missing command: $1"; }

wait_for_status(){
  local cmd="$1" want="$2" timeout="$3" start status
  start="$(date +%s)"
  while true; do
    status="$($cmd || true)"
    [[ "$status" == "$want" ]] && return 0
    (( $(date +%s) - start > timeout )) && { echo "Timeout waiting for $want (last: $status)"; return 1; }
    sleep "$POLL_INTERVAL"
  done
}

ensure_local_pubkey(){
  if [[ ! -f "$PUB_KEY_FILE" ]]; then
    echo "No $PUB_KEY_FILE — generating SSH keypair..."
    mkdir -p "$HOME/.ssh"
    ssh-keygen -t rsa -b 4096 -f "${PUB_KEY_FILE%.pub}" -N ""
  fi
}

ensure_os_keypair(){
  if ! openstack keypair list -f value -c Name | grep -qx "$OS_KEYPAIR"; then
    echo "Creating OpenStack keypair '$OS_KEYPAIR' from $PUB_KEY_FILE ..."
    openstack keypair create --public-key "$PUB_KEY_FILE" "$OS_KEYPAIR" >/dev/null
  else
    echo "Keypair '$OS_KEYPAIR' exists."
  fi
}

cleanup(){
  echo "--- cleanup starting ---"
  if [[ -n "$SERVER_ID" ]] && openstack server show "$SERVER_ID" &>/dev/null; then
    echo "Deleting server $SERVER_ID ..."
    openstack server delete "$SERVER_ID" || true
    until ! openstack server show "$SERVER_ID" &>/dev/null; do sleep 3; done
  fi
  for pid in "$PROV_PORT_ID" "$DATA_PORT_ID"; do
    if [[ -n "$pid" ]] && openstack port show "$pid" &>/dev/null; then
      echo "Deleting port $pid ..."
      openstack port delete "$pid" || true
    fi
  done
  echo "--- cleanup done ---"
}

on_error(){
  local rc=$?
  echo "---- FAIL (rc=$rc). Last 80 log lines ----"
  tail -n 80 "$LOG_FILE" || true
  cleanup
  exit $rc
}
trap on_error ERR

# ============ Pre-flight ============
need openstack
need ssh-keygen

openstack flavor show "$WRK01_FLAVOR_NAME"          >/dev/null
openstack image  show "$WRK01_IMAGE_ID"             >/dev/null
openstack network show "$PROV_NET_ID"               >/dev/null
openstack subnet  show "$PROV_SUBNET_ID"            >/dev/null
openstack network show "$TENANT_NET_ID"             >/dev/null
openstack subnet  show "$TENANT_SUBNET_ID"          >/dev/null

ensure_local_pubkey
ensure_os_keypair

# ============ Minimal cloud-init ============
USER_DATA_FILE="$(pwd)/${SERVER_NAME}_user_data.yaml"
cat > "$USER_DATA_FILE" <<'YAML'
#cloud-config
package_update: true
package_upgrade: false
runcmd:
  - echo "cloud-init completed" | tee /var/log/cloud-init-orchestrator.log
YAML

# ============ Create provisioning VIF (PXE MAC) ============
echo "Creating provisioning port on PXE MAC $PXE_MAC ..."
PROV_PORT_ID="$(openstack port create "$PROV_PORT_NAME" \
  --network "$PROV_NET_ID" \
  --fixed-ip "subnet=$PROV_SUBNET_ID" \
  --mac-address "$PXE_MAC" \
  --vnic-type baremetal \
  --disable-port-security \
  -f value -c id)"
openstack port show "$PROV_PORT_ID" -f yaml | egrep -i 'id:|name:|mac_address:|fixed_ips:|status:'

# ============ Create chamber/data VIF (fixed 10.154.180.52 on DATA MAC) ============
echo "Creating chamber port on MAC $DATA_MAC with fixed IP $TENANT_FIXED_IP ..."
DATA_PORT_ID="$(openstack port create "$DATA_PORT_NAME" \
  --network "$TENANT_NET_ID" \
  --fixed-ip "subnet=${TENANT_SUBNET_ID},ip-address=${TENANT_FIXED_IP}" \
  --mac-address "$DATA_MAC" \
  --vnic-type baremetal \
  --disable-port-security \
  -f value -c id)"
openstack port show "$DATA_PORT_ID" -f yaml | egrep -i 'id:|name:|mac_address:|fixed_ips:|status:'

# ============ Boot from IMAGE with both NICs ============
echo "Booting baremetal server $SERVER_NAME from image with provisioning + chamber NICs ..."
SERVER_ID="$(
  openstack server create "$SERVER_NAME" \
    --flavor "$WRK01_FLAVOR_NAME" \
    --image "$WRK01_IMAGE_ID" \
    --nic "port-id=$PROV_PORT_ID" \
    --nic "port-id=$DATA_PORT_ID" \
    --key-name "$OS_KEYPAIR" \
    --user-data "$USER_DATA_FILE" \
    --property env="$ENVIRONMENT" \
    --property hyperscaler="$HYPERSCALER_TAG" \
    --property capabilities:boot_option="local" \
    -f value -c id
)"
echo "SERVER_ID=$SERVER_ID"

echo "Waiting for server ACTIVE..."
wait_for_status "openstack server show $SERVER_ID -f value -c status" "ACTIVE" "$WAIT_SEC_SERVER"

echo "Server is ACTIVE."
openstack server show "$SERVER_ID" -f yaml | egrep -i 'status:|addresses:|id:|name:'

# ============ Post: disable provisioning VIF (keep chamber only) ============
echo "Disabling provisioning port $PROV_PORT_ID ..."
openstack port set --disable "$PROV_PORT_ID"

# If you prefer to detach+delete instead of disable, use:
# openstack server remove port "$SERVER_ID" "$PROV_PORT_ID"
# openstack port delete "$PROV_PORT_ID"
# PROV_PORT_ID=""

echo "Done. Chamber IP should be ${TENANT_FIXED_IP}."
echo "Log: $LOG_FILE"





































Terraform will perform the following actions:

  # null_resource.config_chef will be created
  + resource "null_resource" "config_chef" {
      + id       = (known after apply)
      + triggers = {
          + "always_run" = (known after apply)
        }
    }

  # openstack_networking_floatingip_v2.fips["cla-eni"] will be created
  + resource "openstack_networking_floatingip_v2" "fips" {
      + address    = "10.107.168.51"
      + all_tags   = (known after apply)
      + dns_domain = (known after apply)
      + dns_name   = (known after apply)
      + fixed_ip   = (known after apply)
      + id         = (known after apply)
      + pool       = "pro-net-vlan1168"
      + port_id    = (known after apply)
      + region     = (known after apply)
      + subnet_id  = (known after apply)
      + tenant_id  = (known after apply)
    }

  # openstack_networking_floatingip_v2.fips["haproxy-eni"] will be created
  + resource "openstack_networking_floatingip_v2" "fips" {
      + address    = "10.107.168.52"
      + all_tags   = (known after apply)
      + dns_domain = (known after apply)
      + dns_name   = (known after apply)
      + fixed_ip   = (known after apply)
      + id         = (known after apply)
      + pool       = "pro-net-vlan1168"
      + port_id    = (known after apply)
      + region     = (known after apply)
      + subnet_id  = (known after apply)
      + tenant_id  = (known after apply)
    }

  # module.baremetal-vm["wrk01"].openstack_compute_instance_v2.instance will be created
  + resource "openstack_compute_instance_v2" "instance" {
      + access_ip_v4        = (known after apply)
      + access_ip_v6        = (known after apply)
      + all_metadata        = (known after apply)
      + all_tags            = (known after apply)
      + availability_zone   = (known after apply)
      + created             = (known after apply)
      + flavor_id           = (known after apply)
      + flavor_name         = "baremetal"
      + force_delete        = false
      + id                  = (known after apply)
      + image_id            = "34504ee6-d6ed-4ba7-a366-647bfee3cd49"
      + image_name          = (known after apply)
      + key_pair            = "c30-to-test-to-01-wrk01-keypair"
      + name                = "to01wrk01"
      + power_state         = "active"
      + region              = (known after apply)
      + security_groups     = (known after apply)
      + stop_before_destroy = false
      + tags                = [
          + "BU:IT",
          + "Backup:none",
          + "BusinessUnit:cloudeng",
          + "Environment:Non-Production",
          + "OrganizationName:IT",
          + "Sub_BU:VCAD",
          + "Terraform:false",
          + "hyperscaler:rhops",
          + "todestroy:false",
          + "tosuspend:false",
        ]
      + updated             = (known after apply)
      + user_data           = (sensitive value)

      + network {
          + access_network = false
          + fixed_ip_v4    = (known after apply)
          + fixed_ip_v6    = (known after apply)
          + mac            = (known after apply)
          + name           = (known after apply)
          + port           = (known after apply)
          + uuid           = (known after apply)
        }
      + network {
          + access_network = false
          + fixed_ip_v4    = (known after apply)
          + fixed_ip_v6    = (known after apply)
          + mac            = (known after apply)
          + name           = (known after apply)
          + port           = (known after apply)
          + uuid           = (known after apply)
        }
    }

  # module.baremetal-vm["wrk01"].openstack_compute_keypair_v2.keypair will be created
  + resource "openstack_compute_keypair_v2" "keypair" {
      + fingerprint = (known after apply)
      + id          = (known after apply)
      + name        = "c30-to-test-to-01-wrk01-keypair"
      + private_key = (sensitive value)
      + public_key  = <<-EOT
            ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQCxUDoGoVa1PkHdBD3AFsFYVCgn3CDi0DuNRyoVxbQ32USl45KbFzrE8nQ5C3+jX/wbZMBuPqM6sWFF8101RcjMxRRyetU126gVqZ3EOLmvAMwKI9SrIqvoalZaWha6HjT+nXfyKAz5v46A/nc/x6iaUqwaTqfc+NtDybhaz3ydb2dlTArCBtKGDV2voy9Qwwyhvbz9jdW7OwRI/FSMTqHZdIGSanJjuM6lUXDZbjrUR8uyUkxjWw+Yfvy9OhySXJW7gu39W+R4XYjdVSiyx1lDY8KL92gq7q0YFm/EAas8MFZXEA6VsEx7BbmC+ZFgrO50+O+rBLVVjty6GLDWGNKSGR3moWZz/KfrBeEpwz/koDEdtONDuXxXBocovckjSi1UVKsP5lGacoZSydnTHxoUiykPgmolbh9Be5opNYEolQqteQ+fGC0ddKIIlNgfZ/f5Pg7jAY24GmdS5JwaGqSHcF9cnB+EqjJocHFJkZf5fa9A1P8dvsVdRjT0VntBjFq4nEVOQ67GYzpwWOqm5vj8WdjdVm36jXuH9d7hJ7IaeWAj0Ep1CAabbEDhZRX0vWDdz/yEahVOJZ2qTGN3Yt23zbn40yu9CCSLLpqxK+gIx/0hq1bRSX5v+0/gAVxPLKOa0FN2qygVdAfVA82IEHIIevIl09ontqFEvuFdDNO6Tw== orchestrator@cc.***.com
        EOT
      + region      = (known after apply)
      + user_id     = (known after apply)
    }

  # module.baremetal-vm["wrk01"].openstack_networking_port_v2.baremetal_provisioning[0] will be created
  + resource "openstack_networking_port_v2" "baremetal_provisioning" {
      + admin_state_up         = true
      + all_fixed_ips          = (known after apply)
      + all_security_group_ids = (known after apply)
      + all_tags               = (known after apply)
      + device_id              = (known after apply)
      + device_owner           = (known after apply)
      + dns_assignment         = (known after apply)
      + dns_name               = (known after apply)
      + id                     = (known after apply)
      + mac_address            = (known after apply)
      + network_id             = "5c79a1a8-b294-4435-a2e6-ef1b992735d3"
      + port_security_enabled  = (known after apply)
      + qos_policy_id          = (known after apply)
      + region                 = (known after apply)
      + tenant_id              = (known after apply)

      + binding (known after apply)
    }

  # module.baremetal-vm["wrk01"].openstack_networking_port_v2.port_1 will be created
  + resource "openstack_networking_port_v2" "port_1" {
      + admin_state_up         = true
      + all_fixed_ips          = (known after apply)
      + all_security_group_ids = (known after apply)
      + all_tags               = (known after apply)
      + device_id              = (known after apply)
      + device_owner           = (known after apply)
      + dns_assignment         = (known after apply)
      + dns_name               = (known after apply)
      + id                     = (known after apply)
      + mac_address            = (known after apply)
      + network_id             = (known after apply)
      + port_security_enabled  = (known after apply)
      + qos_policy_id          = (known after apply)
      + region                 = (known after apply)
      + security_group_ids     = [
          + "13d31d0a-cd07-4b72-bd93-4e615d38775e",
          + "457b2f12-8770-44ef-b94f-57851ec7f18b",
          + "b0812e2a-b6c3-4c60-96b6-ce138448f747",
          + "dbdb464d-50dd-459f-bcf0-51772c729c23",
        ]
      + tenant_id              = (known after apply)

      + binding (known after apply)

      + fixed_ip {
          + ip_address = "10.107.168.101"
          + subnet_id  = (known after apply)
        }
    }

  # module.provider-network.openstack_networking_network_v2.generic will be created
  + resource "openstack_networking_network_v2" "generic" {
      + admin_state_up          = true
      + all_tags                = (known after apply)
      + availability_zone_hints = (known after apply)
      + description             = "Add description"
      + dns_domain              = (known after apply)
      + external                = true
      + id                      = (known after apply)
      + mtu                     = (known after apply)
      + name                    = "pro-net-vlan1168"
      + port_security_enabled   = (known after apply)
      + qos_policy_id           = (known after apply)
      + region                  = "regionOne"
      + shared                  = false
      + tags                    = [
          + "BU:IT",
          + "Backup:none",
          + "BusinessUnit:cloudeng",
          + "Environment:Non-Production",
          + "OrganizationName:IT",
          + "Sub_BU:VCAD",
          + "Terraform:false",
          + "hyperscaler:rhops",
          + "todestroy:false",
          + "tosuspend:false",
        ]
      + tenant_id               = (known after apply)
      + transparent_vlan        = (known after apply)

      + segments {
          + network_type     = "vlan"
          + physical_network = "datacentre"
          + segmentation_id  = 1168
        }
    }

  # module.provider-network.openstack_networking_subnet_v2.subnet["subnet-1168"] will be created
  + resource "openstack_networking_subnet_v2" "subnet" {
      + all_tags          = (known after apply)
      + cidr              = "10.107.168.0/23"
      + dns_nameservers   = [
          + "10.202.56.11",
          + "10.202.56.12",
        ]
      + enable_dhcp       = true
      + gateway_ip        = "10.107.169.254"
      + id                = (known after apply)
      + ip_version        = 4
      + ipv6_address_mode = (known after apply)
      + ipv6_ra_mode      = (known after apply)
      + name              = "pro-subnet-1168"
      + network_id        = (known after apply)
      + no_gateway        = false
      + region            = "regionOne"
      + service_types     = (known after apply)
      + tags              = [
          + "BU:IT",
          + "Backup:none",
          + "BusinessUnit:cloudeng",
          + "Environment:Non-Production",
          + "OrganizationName:IT",
          + "Sub_BU:VCAD",
          + "Terraform:false",
          + "hyperscaler:rhops",
          + "todestroy:false",
          + "tosuspend:false",
        ]
      + tenant_id         = (known after apply)

      + allocation_pool {
          + end   = "10.107.169.232"
          + start = "10.107.168.2"
        }
    }

  # module.router.openstack_networking_port_v2.router_ports["0"] will be created
  + resource "openstack_networking_port_v2" "router_ports" {
      + admin_state_up         = true
      + all_fixed_ips          = (known after apply)
      + all_security_group_ids = (known after apply)
      + all_tags               = (known after apply)
      + device_id              = (known after apply)
      + device_owner           = (known after apply)
      + dns_assignment         = (known after apply)
      + dns_name               = (known after apply)
      + id                     = (known after apply)
      + mac_address            = (known after apply)
      + name                   = "c30-to-test-to-01-rt-000-port"
      + network_id             = "8d28eca5-da32-485f-98c5-d26abaf86d54"
      + port_security_enabled  = true
      + qos_policy_id          = (known after apply)
      + region                 = (known after apply)
      + tenant_id              = (known after apply)

      + binding (known after apply)

      + fixed_ip {
          + ip_address = "10.154.181.161"
          + subnet_id  = "ad141c60-a177-4d9c-90d5-7d47c37fa590"
        }
    }

  # module.router.openstack_networking_port_v2.router_ports["1"] will be created
  + resource "openstack_networking_port_v2" "router_ports" {
      + admin_state_up         = true
      + all_fixed_ips          = (known after apply)
      + all_security_group_ids = (known after apply)
      + all_tags               = (known after apply)
      + device_id              = (known after apply)
      + device_owner           = (known after apply)
      + dns_assignment         = (known after apply)
      + dns_name               = (known after apply)
      + id                     = (known after apply)
      + mac_address            = (known after apply)
      + name                   = "c30-to-test-to-01-rt-001-port"
      + network_id             = "8d28eca5-da32-485f-98c5-d26abaf86d54"
      + port_security_enabled  = true
      + qos_policy_id          = (known after apply)
      + region                 = (known after apply)
      + tenant_id              = (known after apply)

      + binding (known after apply)

      + fixed_ip {
          + ip_address = "10.154.180.1"
          + subnet_id  = "f09dc8d8-5b9e-4ed2-9ea6-10cbfb3130ec"
        }
    }

  # module.router.openstack_networking_port_v2.router_ports["2"] will be created
  + resource "openstack_networking_port_v2" "router_ports" {
      + admin_state_up         = true
      + all_fixed_ips          = (known after apply)
      + all_security_group_ids = (known after apply)
      + all_tags               = (known after apply)
      + device_id              = (known after apply)
      + device_owner           = (known after apply)
      + dns_assignment         = (known after apply)
      + dns_name               = (known after apply)
      + id                     = (known after apply)
      + mac_address            = (known after apply)
      + name                   = "c30-to-test-to-01-rt-002-port"
      + network_id             = "8d28eca5-da32-485f-98c5-d26abaf86d54"
      + port_security_enabled  = true
      + qos_policy_id          = (known after apply)
      + region                 = (known after apply)
      + tenant_id              = (known after apply)

      + binding (known after apply)

      + fixed_ip {
          + ip_address = "10.154.181.1"
          + subnet_id  = "37ca2518-3288-4b25-b83c-bcbcbb39ed84"
        }
    }

  # module.router.openstack_networking_port_v2.router_ports["3"] will be created
  + resource "openstack_networking_port_v2" "router_ports" {
      + admin_state_up         = true
      + all_fixed_ips          = (known after apply)
      + all_security_group_ids = (known after apply)
      + all_tags               = (known after apply)
      + device_id              = (known after apply)
      + device_owner           = (known after apply)
      + dns_assignment         = (known after apply)
      + dns_name               = (known after apply)
      + id                     = (known after apply)
      + mac_address            = (known after apply)
      + name                   = "c30-to-test-to-01-rt-003-port"
      + network_id             = "8d28eca5-da32-485f-98c5-d26abaf86d54"
      + port_security_enabled  = true
      + qos_policy_id          = (known after apply)
      + region                 = (known after apply)
      + tenant_id              = (known after apply)

      + binding (known after apply)

      + fixed_ip {
          + ip_address = "10.154.181.129"
          + subnet_id  = "1f37ed8a-cac9-46e7-8591-7a7d93617373"
        }
    }

  # module.router.openstack_networking_router_interface_v2.router_interfaces["0"] will be created
  + resource "openstack_networking_router_interface_v2" "router_interfaces" {
      + force_destroy = false
      + id            = (known after apply)
      + port_id       = (known after apply)
      + region        = (known after apply)
      + router_id     = (known after apply)
      + subnet_id     = (known after apply)
    }

  # module.router.openstack_networking_router_interface_v2.router_interfaces["1"] will be created
  + resource "openstack_networking_router_interface_v2" "router_interfaces" {
      + force_destroy = false
      + id            = (known after apply)
      + port_id       = (known after apply)
      + region        = (known after apply)
      + router_id     = (known after apply)
      + subnet_id     = (known after apply)
    }

  # module.router.openstack_networking_router_interface_v2.router_interfaces["2"] will be created
  + resource "openstack_networking_router_interface_v2" "router_interfaces" {
      + force_destroy = false
      + id            = (known after apply)
      + port_id       = (known after apply)
      + region        = (known after apply)
      + router_id     = (known after apply)
      + subnet_id     = (known after apply)
    }

  # module.router.openstack_networking_router_interface_v2.router_interfaces["3"] will be created
  + resource "openstack_networking_router_interface_v2" "router_interfaces" {
      + force_destroy = false
      + id            = (known after apply)
      + port_id       = (known after apply)
      + region        = (known after apply)
      + router_id     = (known after apply)
      + subnet_id     = (known after apply)
    }

  # module.router.openstack_networking_router_v2.routers["RtbInternal"] will be created
  + resource "openstack_networking_router_v2" "routers" {
      + admin_state_up          = true
      + all_tags                = (known after apply)
      + availability_zone_hints = (known after apply)
      + description             = "Default Router"
      + distributed             = (known after apply)
      + enable_snat             = (known after apply)
      + external_network_id     = (known after apply)
      + id                      = (known after apply)
      + name                    = "c30-to-test-to-01-RtbInternal-rt"
      + region                  = "regionOne"
      + tags                    = [
          + "BU:IT",
          + "Backup:none",
          + "BusinessUnit:cloudeng",
          + "Environment:Non-Production",
          + "OrganizationName:IT",
          + "Sub_BU:VCAD",
          + "Terraform:false",
          + "hyperscaler:rhops",
          + "todestroy:false",
          + "tosuspend:false",
        ]
      + tenant_id               = (known after apply)

      + external_fixed_ip {
          + ip_address = "10.107.168.1"
          + subnet_id  = (known after apply)
        }

      + vendor_options {
          + set_router_gateway_after_create = true
        }
    }

Plan: 18 to add, 0 to change, 0 to destroy.

─────────────────────────────────────────────────────────────────────────────


# Auto-cleans port/server on failure.

set -euo pipefail
[[ "${DEBUG:-0}" == "1" ]] && set -x

# ======== Config ========
HYPERSCALER_TAG="rhops"
ENVIRONMENT="test-2"
NAME_PREFIX="to01"
NODE_NAME="wrk01"
SERVER_NAME="${NAME_PREFIX}-${NODE_NAME}-vm"

WRK01_IMAGE_ID="4a31915b-213a-4173-97ad-a582c72ff9f2"
WRK01_FLAVOR_NAME="baremetal"

BAREMETAL_NET_ID="5c79a1a8-b294-4435-a2e6-ef1b992735d3"
BAREMETAL_SUBNET_ID="c83e54b1-822e-4931-ac73-b731d1f6c966"

OS_KEYPAIR="${OS_KEYPAIR:-cloud30-default-kp}"
PUB_KEY_FILE="${PUB_KEY_FILE:-$HOME/.ssh/id_rsa.pub}"

WAIT_SEC_SERVER="${WAIT_SEC_SERVER:-1800}"
POLL_INTERVAL="${POLL_INTERVAL:-5}"

BM_PORT_NAME="${SERVER_NAME}-bm-port"

# ============ Logging ============
RUN_ID="$(date +%Y%m%d-%H%M%S)"
LOG_FILE="${LOG_FILE:-./deploy_${SERVER_NAME}_${RUN_ID}.log}"
exec > >(tee -a "$LOG_FILE") 2>&1

# ============ State ============
PORT_ID=""
SERVER_ID=""

# ============ Helpers ============
die(){ echo "ERROR: $*" >&2; exit 1; }
require_cmd(){ command -v "$1" >/dev/null 2>&1 || die "Missing command: $1"; }

wait_for_status(){
  local cmd="$1" want="$2" timeout="$3" start status
  start="$(date +%s)"
  while true; do
    status="$($cmd || true)"
    [[ "$status" == "$want" ]] && return 0
    (( $(date +%s) - start > timeout )) && { echo "Timeout waiting for $want (last: $status)"; return 1; }
    sleep "$POLL_INTERVAL"
  done
}

ensure_local_pubkey(){
  if [[ ! -f "$PUB_KEY_FILE" ]]; then
    echo "No $PUB_KEY_FILE — generating SSH keypair..."
    mkdir -p "$HOME/.ssh"
    ssh-keygen -t rsa -b 4096 -f "${PUB_KEY_FILE%.pub}" -N ""
  fi
}

ensure_os_keypair(){
  if ! openstack keypair list -f value -c Name | grep -qx "$OS_KEYPAIR"; then
    echo "Creating OpenStack keypair '$OS_KEYPAIR' from $PUB_KEY_FILE ..."
    openstack keypair create --public-key "$PUB_KEY_FILE" "$OS_KEYPAIR" >/dev/null
  else
    echo "Keypair '$OS_KEYPAIR' exists."
  fi
}

cleanup(){
  echo "--- cleanup starting ---"
  if [[ -n "$SERVER_ID" ]] && openstack server show "$SERVER_ID" &>/dev/null; then
    echo "Deleting server $SERVER_ID ..."
    openstack server delete "$SERVER_ID" || true
    until ! openstack server show "$SERVER_ID" &>/dev/null; do sleep 3; done
  fi

  if [[ -n "$PORT_ID" ]] && openstack port show "$PORT_ID" &>/dev/null; then
    echo "Deleting port $PORT_ID ..."
    openstack port delete "$PORT_ID" || true
  fi
  echo "--- cleanup done ---"
}

on_error(){
  local rc=$?
  echo "---- FAIL (rc=$rc). Last 80 log lines ----"
  tail -n 80 "$LOG_FILE" || true
  cleanup
  exit $rc
}
trap on_error ERR

# ============ Pre-flight ============
require_cmd openstack
require_cmd ssh-keygen

openstack flavor show "$WRK01_FLAVOR_NAME" >/dev/null || die "Flavor '$WRK01_FLAVOR_NAME' not found"
openstack image show  "$WRK01_IMAGE_ID"     >/dev/null || die "Image  '$WRK01_IMAGE_ID' not found"
openstack network show "$BAREMETAL_NET_ID"  >/dev/null || die "Network '$BAREMETAL_NET_ID' not found"
openstack subnet show  "$BAREMETAL_SUBNET_ID" >/dev/null || die "Subnet  '$BAREMETAL_SUBNET_ID' not found"

ensure_local_pubkey
ensure_os_keypair

# ============ Cloud-init ============
USER_DATA_FILE="$(pwd)/${SERVER_NAME}_user_data.yaml"
cat > "$USER_DATA_FILE" <<'YAML'
#cloud-config
package_update: true
package_upgrade: false
runcmd:
  - echo "cloud-init completed" | tee /var/log/cloud-init-orchestrator.log
YAML

# ============ Port ============
echo "Creating baremetal port $BM_PORT_NAME ..."
openstack port create "$BM_PORT_NAME" \
  --network "$BAREMETAL_NET_ID" \
  --fixed-ip "subnet=$BAREMETAL_SUBNET_ID" \
  --disable-port-security >/dev/null
PORT_ID="$(openstack port show "$BM_PORT_NAME" -f value -c id)"
echo "PORT_ID=$PORT_ID"

# ============ Server (direct from image) ============
echo "Booting baremetal server $SERVER_NAME from image..."
SERVER_ID="$(
  openstack server create "$SERVER_NAME" \
    --flavor "$WRK01_FLAVOR_NAME" \
    --image "$WRK01_IMAGE_ID" \
    --nic "port-id=$PORT_ID" \
    --key-name "$OS_KEYPAIR" \
    --user-data "$USER_DATA_FILE" \
    --property env="$ENVIRONMENT" \
    --property hyperscaler="$HYPERSCALER_TAG" \
    --property capabilities:boot_option="local" \
    -f value -c id
)"
echo "SERVER_ID=$SERVER_ID"

echo "Waiting for server ACTIVE..."
wait_for_status "openstack server show $SERVER_ID -f value -c status" "ACTIVE" "$WAIT_SEC_SERVER"

echo "=== SUCCESS ==="
openstack server show "$SERVER_ID"
echo "Log: $LOG_FILE"























# ids
NODE="16dec879-ba80-4cac-8486-59318d688037"
PXE_MAC="c4:cb:e1:dd:19:6e"
IR_PORT_UUID="31cdcec5-ab6b-4f81-bb2f-fbfdc6d5b7e4"
PROV_NET_ID="5c79a1a8-b294-4435-a2e6-ef1b992735d3"
PROV_SUBNET_ID="c83e54b1-822e-4931-ac73-b731d1f6c966"
IMG_ID="4a31915b-213a-4173-97ad-a582c72ff9f2"

# 7.1 Create a VIF (Neutron port) on the provisioning network for the PXE MAC
VIF_NAME="to01-wrk01-prov-vif-pxe"
NEUTRON_PORT_ID=$(openstack port create "$VIF_NAME" \
  --network "$PROV_NET_ID" \
  --fixed-ip "subnet=${PROV_SUBNET_ID}" \
  --mac-address "$PXE_MAC" \
  --vnic-type baremetal \
  --disable-port-security \
  -f value -c id)

openstack port show "$NEUTRON_PORT_ID"

# 7.2 Attach the VIF to the node’s PXE Ironic port
openstack baremetal node vif attach \
  --port-uuid "$IR_PORT_UUID" \
  "$NODE" \
  "$NEUTRON_PORT_ID"

# (optional) confirm attachment
openstack baremetal node vif list "$NODE"

# 7.3 Set image to deploy
openstack baremetal node set "$NODE" --instance-info "image_source=$IMG_ID"

# 7.4 Deploy
openstack baremetal node deploy "$NODE"

# Follow progress
watch -n 5 "openstack baremetal node show $NODE -f value -c provision_state -c last_error"












set -euo pipefail
[[ "${DEBUG:-0}" == "1" ]] && set -x

# ======== Config you likely keep ========
HYPERSCALER_TAG="rhops"
ENVIRONMENT="test-2"
NAME_PREFIX="to01"
NODE_NAME="wrk01"
SERVER_NAME="${NAME_PREFIX}-${NODE_NAME}-vm"

WRK01_IMAGE_ID="4a31915b-213a-4173-97ad-a582c72ff9f2"
WRK01_BOOT_SIZE_GB="100"
WRK01_FLAVOR_NAME="baremetal"

BAREMETAL_NET_ID="5c79a1a8-b294-4435-a2e6-ef1b992735d3"
BAREMETAL_SUBNET_ID="c83e54b1-822e-4931-ac73-b731d1f6c966"

OS_KEYPAIR="${OS_KEYPAIR:-cloud30-default-kp}"       # auto-created if missing
PUB_KEY_FILE="${PUB_KEY_FILE:-$HOME/.ssh/id_rsa.pub}"

WAIT_SEC_VOLUME="${WAIT_SEC_VOLUME:-900}"   # 15m
WAIT_SEC_SERVER="${WAIT_SEC_SERVER:-1800}"  # 30m
POLL_INTERVAL="${POLL_INTERVAL:-5}"

BOOT_VOL_NAME="${SERVER_NAME}-root"
BM_PORT_NAME="${SERVER_NAME}-bm-port"

# ============ Logging ============
RUN_ID="$(date +%Y%m%d-%H%M%S)"
LOG_FILE="${LOG_FILE:-./deploy_${SERVER_NAME}_${RUN_ID}.log}"
exec > >(tee -a "$LOG_FILE") 2>&1

# ============ State for cleanup ============
VOL_ID=""
PORT_ID=""
SERVER_ID=""

# ============ Helpers ============
die(){ echo "ERROR: $*" >&2; exit 1; }
require_cmd(){ command -v "$1" >/dev/null 2>&1 || die "Missing command: $1"; }

wait_for_status(){
  local cmd="$1" want="$2" timeout="$3" start status
  start="$(date +%s)"
  while true; do
    status="$($cmd || true)"
    [[ "$status" == "$want" ]] && return 0
    (( $(date +%s) - start > timeout )) && { echo "Timeout waiting for $want (last: $status)"; return 1; }
    sleep "$POLL_INTERVAL"
  done
}

ensure_local_pubkey(){
  if [[ ! -f "$PUB_KEY_FILE" ]]; then
    echo "No $PUB_KEY_FILE — generating SSH keypair..."
    mkdir -p "$HOME/.ssh"
    ssh-keygen -t rsa -b 4096 -f "${PUB_KEY_FILE%.pub}" -N ""
  fi
}

ensure_os_keypair(){
  if ! openstack keypair list -f value -c Name | grep -qx "$OS_KEYPAIR"; then
    echo "Creating OpenStack keypair '$OS_KEYPAIR' from $PUB_KEY_FILE ..."
    openstack keypair create --public-key "$PUB_KEY_FILE" "$OS_KEYPAIR" >/dev/null
  else
    echo "Keypair '$OS_KEYPAIR' exists."
  fi
}

cleanup(){
  echo "--- cleanup starting ---"
  # delete server if exists
  if [[ -n "$SERVER_ID" ]] && openstack server show "$SERVER_ID" &>/dev/null; then
    echo "Deleting server $SERVER_ID ..."
    openstack server delete "$SERVER_ID" || true
    # wait until gone
    until ! openstack server show "$SERVER_ID" &>/dev/null; do sleep 3; done
  fi

  # delete port
  if [[ -n "$PORT_ID" ]] && openstack port show "$PORT_ID" &>/dev/null; then
    echo "Deleting port $PORT_ID ..."
    openstack port delete "$PORT_ID" || true
  fi

  # detach (if somehow attached) and delete volume
  if [[ -n "$VOL_ID" ]] && openstack volume show "$VOL_ID" &>/dev/null; then
    echo "Deleting volume $VOL_ID ..."
    openstack volume set --read-only False "$VOL_ID" 2>/dev/null || true
    openstack volume delete "$VOL_ID" || true
  fi
  echo "--- cleanup done ---"
}

on_error(){
  local rc=$?
  echo "---- FAIL (rc=$rc). Last 80 log lines ----"
  tail -n 80 "$LOG_FILE" || true
  cleanup
  exit $rc
}
trap on_error ERR

# ============ Pre-flight ============
require_cmd openstack
require_cmd ssh-keygen

openstack flavor show "$WRK01_FLAVOR_NAME" >/dev/null || die "Flavor '$WRK01_FLAVOR_NAME' not found"
openstack image show  "$WRK01_IMAGE_ID"     >/dev/null || die "Image  '$WRK01_IMAGE_ID' not found"
openstack network show "$BAREMETAL_NET_ID"  >/dev/null || die "Network '$BAREMETAL_NET_ID' not found"
openstack subnet show  "$BAREMETAL_SUBNET_ID" >/dev/null || die "Subnet  '$BAREMETAL_SUBNET_ID' not found"

ensure_local_pubkey
ensure_os_keypair

# ============ Cloud-init (minimal) ============
USER_DATA_FILE="$(pwd)/${SERVER_NAME}_user_data.yaml"
cat > "$USER_DATA_FILE" <<'YAML'
#cloud-config
package_update: true
package_upgrade: false
runcmd:
  - echo "cloud-init completed" | tee /var/log/cloud-init-orchestrator.log
YAML

# ============ Volume ============
echo "Creating boot volume $BOOT_VOL_NAME from image..."
openstack volume create "$BOOT_VOL_NAME" \
  --size "$WRK01_BOOT_SIZE_GB" \
  --image "$WRK01_IMAGE_ID" >/dev/null
VOL_ID="$(openstack volume show "$BOOT_VOL_NAME" -f value -c id)"
echo "VOL_ID=$VOL_ID"
echo "Waiting for volume to be available..."
wait_for_status "openstack volume show $BOOT_VOL_NAME -f value -c status" "available" "$WAIT_SEC_VOLUME"

# ============ Port ============
echo "Creating baremetal port $BM_PORT_NAME ..."

PXE_MAC="6c:92:cf:27:ce:50"

openstack port create "$BM_PORT_NAME" \
  --network "$BAREMETAL_NET_ID" \
  --mac-address "$PXE_MAC" \
  --fixed-ip "subnet=$BAREMETAL_SUBNET_ID" \
  --disable-port-security >/dev/null

PORT_ID="$(openstack port show "$BM_PORT_NAME" -f value -c id)"
echo "PORT_ID=$PORT_ID"

# ============ Server ============
echo "Booting server $SERVER_NAME ..."
SERVER_ID="$(
  openstack server create "$SERVER_NAME" \
    --flavor "$WRK01_FLAVOR_NAME" \
    --volume "$BOOT_VOL_NAME" \
    --nic "port-id=$PORT_ID" \
    --key-name "$OS_KEYPAIR" \
    --user-data "$USER_DATA_FILE" \
    --property env="$ENVIRONMENT" \
    --property hyperscaler="$HYPERSCALER_TAG" \
    -f value -c id
)"
echo "SERVER_ID=$SERVER_ID"

echo "Waiting for server ACTIVE..."
wait_for_status "openstack server show $SERVER_ID -f value -c status" "ACTIVE" "$WAIT_SEC_SERVER"

echo "=== SUCCESS ==="
openstack server show "$SERVER_ID"
echo "Log: $LOG_FILE"




General
Node ID
16dec879-ba80-4cac-8486-59318d688037
Chassis ID
-
Resource Class
BAREMETAL-LARGE
Created At
Mar 6, 2025 8:21:06 AM
Ports
	 	MAC Address	PXE Enabled	Portgroup	Actions
		c4:cb:e1:dd:19:6e	true	-	
		6c:92:cf:27:ce:50	false	-	
Portgroups
	 	UUID	MAC Address	Name	Ports	Actions
No portgroups have been defined
Driver Info
ipmi_address
10.107.131.54
ipmi_username
admin
ipmi_password
******
deploy_kernel
8d0994b4-3745-49bb-bd21-4bb08289515d
deploy_ramdisk
a54b1998-1937-4c84-af1b-7f5c8f52188e
rescue_kernel
8d0994b4-3745-49bb-bd21-4bb08289515d
rescue_ramdisk
a54b1998-1937-4c84-af1b-7f5c8f52188e
Driver Validation
Interface	Valid	Current Interface	Reason
boot		ipxe	
deploy		direct	Node 16dec879-ba80-4cac-8486-59318d688037 failed to validate deploy image info. Some parameters were missing. Missing are: ['instance_info.image_source']
management		ipmitool	
network		flat	
power		ipmitool	
bios			Driver ipmi does not support bios (disabled or not implemented).
console		ipmitool-socat	Either missing 'ipmi_terminal_port' parameter in node's driver_info or [console]port_range is not configured
inspect		inspector	
raid		no-raid	Driver ipmi does not support raid (disabled or not implemented).
rescue			Node 16dec879-ba80-4cac-8486-59318d688037 is missing 'instance_info/rescue_password'. It is required for rescuing node.
storage		noop	
Properties
capabilities
cpu_vt:true,cpu_aes:true,cpu_hugepages:true,cpu_hugepages_1g:true,cpu_txt:true
cpus
128
vendor
dell inc
memory_mb
1048576
local_gb
1787
cpu_arch
x86_64
Instance Info
Extra
Boot Device
Device
-
Persistent
false



















# === IDs you already have ===
NODE="16dec879-ba80-4cac-8486-59318d688037"

# Ironic port that matches the MAC which already has a Neutron port record
IR_PORT_UUID="3112f148-b6f6-4e5b-ad3d-e08bf1db550b"   # MAC 6c:92:cf:27:ce:50

# Existing Neutron port you found on the provisioning subnet (Status: DOWN)
NEUTRON_PORT_ID="9eeeaad6-a641-488f-a12f-99b014cf9334"  # Name: to01-wrk01-vm-bm-port

# Glance image you want to deploy
IMG_ID="4a31915b-213a-4173-97ad-a582c72ff9f2"          # cc-rhel86-baremetal-uefi


# --- 1) Make sure node is clean & AVAILABLE (no destructive wipe) ---
openstack baremetal node maintenance set "$NODE" || true
openstack baremetal node unset "$NODE" --instance-info || true
openstack baremetal node unset "$NODE" --instance-uuid || true
openstack baremetal node power off "$NODE" 2>/dev/null || true
openstack baremetal node maintenance unset "$NODE" || true
openstack baremetal node manage "$NODE" || true
openstack baremetal node provide "$NODE" || true
until [[ "$(openstack baremetal node show "$NODE" -f value -c provision_state)" == "available" ]]; do sleep 2; done
openstack baremetal node show "$NODE" -f value -c provision_state


# --- 2) Attach the EXISTING Neutron VIF to the chosen Ironic (hardware) port ---
# (Requires the ironic plugin; see note below if this command isn’t recognized)
openstack baremetal node vif attach \
  --port-uuid "$IR_PORT_UUID" \
  "$NODE" \
  "$NEUTRON_PORT_ID"

# sanity: the Neutron port should now show a device_owner/device_id after attach (optional)
openstack port show "$NEUTRON_PORT_ID"


# --- 3) Tell Ironic which image to deploy, then deploy ---
openstack baremetal node set "$NODE" --instance-info "image_source=$IMG_ID"

openstack baremetal node deploy "$NODE"

# follow progress
watch -n 5 "openstack baremetal node show $NODE -f value -c provision_state -c last_error"

























sjcvl-ghrunner1:~% bash
vsaravan@sjcvl-ghrunner1:~$ source /home/srinip/test_os.sh
Please enter your OpenStack Password for project cc-test-oa-chm01-prj as user svc-account-dev-01:
vsaravan@sjcvl-ghrunner1:~$ NODE="16dec879-ba80-4cac-8486-59318d688037"
vsaravan@sjcvl-ghrunner1:~$ PROV_NET_ID="5c79a1a8-b294-4435-a2e6-ef1b992735d3"
vsaravan@sjcvl-ghrunner1:~$ PROV_SUBNET_ID="c83e54b1-822e-4931-ac73-b731d1f6c966"
vsaravan@sjcvl-ghrunner1:~$ IMG_ID="4a31915b-213a-4173-97ad-a582c72ff9f2"
vsaravan@sjcvl-ghrunner1:~$ FLAVOR="baremetal"
vsaravan@sjcvl-ghrunner1:~$ openstack baremetal node show "$NODE" -f yaml | egrep -i \
> 'uuid:|name:|provision_state:|last_error:|maintenance:|power_state:|deploy_boot_mode:|instance_uuid:'
allocation_uuid: null
chassis_uuid: null
  ipmi_username: admin
  deploy_boot_mode: uefi
instance_uuid: null
last_error: null
maintenance: true
name: baremetal-node-1
power_state: power off
provision_state: deploy failed
target_power_state: null
target_provision_state: active
uuid: 16dec879-ba80-4cac-8486-59318d688037
vsaravan@sjcvl-ghrunner1:~$ openstack baremetal port list --node "$NODE" -f yaml
- Address: c4:cb:e1:dd:19:6e
  UUID: 31cdcec5-ab6b-4f81-bb2f-fbfdc6d5b7e4
- Address: 6c:92:cf:27:ce:50
  UUID: 3112f148-b6f6-4e5b-ad3d-e08bf1db550b
vsaravan@sjcvl-ghrunner1:~$ openstack baremetal vif list "$NODE" -f yaml || echo "vif list not available"
openstack: 'baremetal vif list 16dec879-ba80-4cac-8486-59318d688037 -f yaml' is not an openstack command. See 'openstack --help'.


vsaravan@sjcvl-ghrunner1:~$ openstack port list --network "$PROV_NET_ID" -f yaml | egrep -i \
> ^C
vsaravan@sjcvl-ghrunner1:~$ openstack port list --network "$PROV_NET_ID" -f yaml | egrep -i \
> 'id:|name:|status:|binding_vnic_type:|port_security_enabled:|device_owner:|fixed_ips:'
    subnet_id: c83e54b1-822e-4931-ac73-b731d1f6c966
  ID: 24cfa46e-9a84-43d5-9df0-d3f57635ff38
  Name: ''
  Status: ACTIVE
    subnet_id: c83e54b1-822e-4931-ac73-b731d1f6c966
  ID: 449c9d51-9c3b-43af-9f72-41b52a0182a0
  Name: ''
  Status: DOWN
    subnet_id: c83e54b1-822e-4931-ac73-b731d1f6c966
  ID: 45ab2cb0-6746-446a-8982-654456fcf476
  Name: baremetal-1
  Status: ACTIVE
    subnet_id: c83e54b1-822e-4931-ac73-b731d1f6c966
  ID: 8b660750-4906-4d25-aea2-7a60c1557f89
  Name: ''
  Status: DOWN
    subnet_id: c83e54b1-822e-4931-ac73-b731d1f6c966
  ID: 9eeeaad6-a641-488f-a12f-99b014cf9334
  Name: to01-wrk01-vm-bm-port
  Status: DOWN
    subnet_id: c83e54b1-822e-4931-ac73-b731d1f6c966
  ID: c0e9f605-0572-4d49-9c36-7aba37e3c939
  Name: ''
  Status: DOWN
    subnet_id: c83e54b1-822e-4931-ac73-b731d1f6c966
  ID: c16fd492-12d8-4437-b3f9-f0b4b2b1c183
  Name: ''
  Status: ACTIVE
    subnet_id: c83e54b1-822e-4931-ac73-b731d1f6c966
  ID: cc483c71-adbd-413c-8243-3108965d6350
  Name: ''
  Status: DOWN
    subnet_id: c83e54b1-822e-4931-ac73-b731d1f6c966
  ID: ef0c588b-a925-4988-ba41-0c0e4e1cfdeb
  Name: ''
  Status: ACTIVE
    subnet_id: c83e54b1-822e-4931-ac73-b731d1f6c966
  ID: fba274d3-9e34-45e7-9761-79311faaf623
  Name: ''
  Status: ACTIVE
vsaravan@sjcvl-ghrunner1:~$ ^C
vsaravan@sjcvl-ghrunner1:~$ IR_MACS=$(openstack baremetal port list --node "$NODE" -f value -c Address)
vsaravan@sjcvl-ghrunner1:~$ echo "$IR_MACS" | while read -r mac; do
>   echo "---- Neutron ports with MAC $mac ----"
>   openstack port list --mac-address "$mac" -f yaml | egrep -i \
>   'id:|name:|network_id:|status:|binding_vnic_type:|port_security_enabled:|fixed_ips:|device_owner:' || true
> done
---- Neutron ports with MAC c4:cb:e1:dd:19:6e ----
    subnet_id: 23492042-0c36-4895-9224-03b798c3921b
  ID: 5687c175-72fd-4b02-ae7c-e838e89c39ca
  Name: ''
  Status: DOWN
    subnet_id: 0c8eab23-6f0b-4e81-864b-77a143a4d1b3
  ID: b88407d2-ea0d-4ae3-bb63-c7bbee100741
  Name: ''
  Status: DOWN
---- Neutron ports with MAC 6c:92:cf:27:ce:50 ----
    subnet_id: c83e54b1-822e-4931-ac73-b731d1f6c966
  ID: 9eeeaad6-a641-488f-a12f-99b014cf9334
  Name: to01-wrk01-vm-bm-port
  Status: DOWN
vsaravan@sjcvl-ghrunner1:~$ openstack network show "$PROV_NET_ID" -f yaml | egrep -i \
> 'name:|id:|provider:network_type:|provider:physical_network:|provider:segmentation_id:|shared:|port_security_enabled:'
id: 5c79a1a8-b294-4435-a2e6-ef1b992735d3
name: provisioning
port_security_enabled: true
project_id: 334ca1da01cc4820b35c604cb37a5c1e
provider:network_type: flat
provider:physical_network: baremetal
provider:segmentation_id: null
qos_policy_id: null
shared: true
tenant_id: 334ca1da01cc4820b35c604cb37a5c1e
vsaravan@sjcvl-ghrunner1:~$ openstack subnet show "$PROV_SUBNET_ID" -f yaml | egrep -i \
> 'name:|id:|cidr:|enable_dhcp:|gateway_ip:'
cidr: 10.107.177.0/24
enable_dhcp: true
gateway_ip: 10.107.177.254
id: c83e54b1-822e-4931-ac73-b731d1f6c966
name: provisioning-subnet
network_id: 5c79a1a8-b294-4435-a2e6-ef1b992735d3
project_id: 334ca1da01cc4820b35c604cb37a5c1e
segment_id: null
subnetpool_id: null
vsaravan@sjcvl-ghrunner1:~$ openstack image show "$IMG_ID" -f yaml | egrep -i 'name:|disk_format:|container_format:|min_disk:|hw_firmware_type:|status:'

container_format: bare
disk_format: qcow2
min_disk: 100
name: cc-rhel86-baremetal-uefi
status: active
vsaravan@sjcvl-ghrunner1:~$ openstack flavor show "$FLAVOR" -f yaml | egrep -i 'name:|id:|properties:|resources:'
id: auto
name: baremetal
properties:
  resources:CUSTOM_BAREMETAL_LARGE: '1'
  resources:DISK_GB: '0'
  resources:MEMORY_MB: '0'
  resources:VCPU: '0'
vsaravan@sjcvl-ghrunner1:~$

vsaravan@sjcvl-ghrunner1:~$ openstack baremetal node list




# 0) Set variables (adjust if needed)
NODE="16dec879-ba80-4cac-8486-59318d688037"
PROV_NET_ID="5c79a1a8-b294-4435-a2e6-ef1b992735d3"
PROV_SUBNET_ID="c83e54b1-822e-4931-ac73-b731d1f6c966"
IMG_ID="4a31915b-213a-4173-97ad-a582c72ff9f2"
FLAVOR="baremetal"

# 1) Node high-level status
openstack baremetal node show "$NODE" -f yaml | egrep -i \
'uuid:|name:|provision_state:|last_error:|maintenance:|power_state:|deploy_boot_mode:|instance_uuid:'

# 2) Ironic hardware ports (MAC addresses)
openstack baremetal port list --node "$NODE" -f yaml

# 3) Existing VIF attachments (if API supported)
openstack baremetal vif list "$NODE" -f yaml || echo "vif list not available"

# 4) Neutron ports on provisioning network
openstack port list --network "$PROV_NET_ID" -f yaml | egrep -i \
'id:|name:|status:|binding_vnic_type:|port_security_enabled:|device_owner:|fixed_ips:'

# 5) Correlate Neutron ports by MAC
IR_MACS=$(openstack baremetal port list --node "$NODE" -f value -c Address)
echo "$IR_MACS" | while read -r mac; do
  echo "---- Neutron ports with MAC $mac ----"
  openstack port list --mac-address "$mac" -f yaml | egrep -i \
  'id:|name:|network_id:|status:|binding_vnic_type:|port_security_enabled:|fixed_ips:|device_owner:' || true
done

# 6) Provisioning network/subnet details
openstack network show "$PROV_NET_ID" -f yaml | egrep -i \
'name:|id:|provider:network_type:|provider:physical_network:|provider:segmentation_id:|shared:|port_security_enabled:'
openstack subnet show "$PROV_SUBNET_ID" -f yaml | egrep -i \
'name:|id:|cidr:|enable_dhcp:|gateway_ip:'

# 7) Image & flavor sanity
openstack image show "$IMG_ID" -f yaml | egrep -i 'name:|disk_format:|container_format:|min_disk:|hw_firmware_type:|status:'
openstack flavor show "$FLAVOR" -f yaml | egrep -i 'name:|id:|properties:|resources:'
























+--------------------------------------+------------------+---------------+-------------+--------------------+-------------+
| UUID                                 | Name             | Instance UUID | Power State | Provisioning State | Maintenance |
+--------------------------------------+------------------+---------------+-------------+--------------------+-------------+
| 16dec879-ba80-4cac-8486-59318d688037 | baremetal-node-1 | None          | power off   | deploy failed      | True        |
+--------------------------------------+------------------+---------------+-------------+--------------------+-------------+
vsaravan@sjcvl-ghrunner1:~$ openstack baremetal node show <node-id> -f value -c provision_state^C
vsaravan@sjcvl-ghrunner1:~$ nano create_bare_scriptpt.sh
vsaravan@sjcvl-ghrunner1:~$ cat  create_bare_scriptpt.sh
#!/usr/bin/env bash
# Minimal baremetal bring-up (expects OS_* already sourced)
# Auto-cleans volume/port/server on failure.

set -euo pipefail
[[ "${DEBUG:-0}" == "1" ]] && set -x

# ======== Config you likely keep ========
HYPERSCALER_TAG="rhops"
ENVIRONMENT="test-2"
NAME_PREFIX="to01"
NODE_NAME="wrk01"
SERVER_NAME="${NAME_PREFIX}-${NODE_NAME}-vm"

WRK01_IMAGE_ID="4a31915b-213a-4173-97ad-a582c72ff9f2"
WRK01_BOOT_SIZE_GB="100"
WRK01_FLAVOR_NAME="baremetal"

BAREMETAL_NET_ID="5c79a1a8-b294-4435-a2e6-ef1b992735d3"
BAREMETAL_SUBNET_ID="c83e54b1-822e-4931-ac73-b731d1f6c966"

OS_KEYPAIR="${OS_KEYPAIR:-cloud30-default-kp}"       # auto-created if missing
PUB_KEY_FILE="${PUB_KEY_FILE:-$HOME/.ssh/id_rsa.pub}"

WAIT_SEC_VOLUME="${WAIT_SEC_VOLUME:-900}"   # 15m
WAIT_SEC_SERVER="${WAIT_SEC_SERVER:-1800}"  # 30m
POLL_INTERVAL="${POLL_INTERVAL:-5}"

BOOT_VOL_NAME="${SERVER_NAME}-root"
BM_PORT_NAME="${SERVER_NAME}-bm-port"

# ============ Logging ============
RUN_ID="$(date +%Y%m%d-%H%M%S)"
LOG_FILE="${LOG_FILE:-./deploy_${SERVER_NAME}_${RUN_ID}.log}"
exec > >(tee -a "$LOG_FILE") 2>&1

# ============ State for cleanup ============
VOL_ID=""
PORT_ID=""
SERVER_ID=""

# ============ Helpers ============
die(){ echo "ERROR: $*" >&2; exit 1; }
require_cmd(){ command -v "$1" >/dev/null 2>&1 || die "Missing command: $1"; }

wait_for_status(){
  local cmd="$1" want="$2" timeout="$3" start status
  start="$(date +%s)"
  while true; do
    status="$($cmd || true)"
    [[ "$status" == "$want" ]] && return 0
    (( $(date +%s) - start > timeout )) && { echo "Timeout waiting for $want (last: $status)"; return 1; }
    sleep "$POLL_INTERVAL"
  done
}

ensure_local_pubkey(){
  if [[ ! -f "$PUB_KEY_FILE" ]]; then
    echo "No $PUB_KEY_FILE — generating SSH keypair..."
    mkdir -p "$HOME/.ssh"
    ssh-keygen -t rsa -b 4096 -f "${PUB_KEY_FILE%.pub}" -N ""
  fi
}

ensure_os_keypair(){
  if ! openstack keypair list -f value -c Name | grep -qx "$OS_KEYPAIR"; then
    echo "Creating OpenStack keypair '$OS_KEYPAIR' from $PUB_KEY_FILE ..."
    openstack keypair create --public-key "$PUB_KEY_FILE" "$OS_KEYPAIR" >/dev/null
  else
    echo "Keypair '$OS_KEYPAIR' exists."
  fi
}

cleanup(){
  echo "--- cleanup starting ---"
  # delete server if exists
  if [[ -n "$SERVER_ID" ]] && openstack server show "$SERVER_ID" &>/dev/null; then
    echo "Deleting server $SERVER_ID ..."
    openstack server delete "$SERVER_ID" || true
    # wait until gone
    until ! openstack server show "$SERVER_ID" &>/dev/null; do sleep 3; done
  fi

  # delete port
  if [[ -n "$PORT_ID" ]] && openstack port show "$PORT_ID" &>/dev/null; then
    echo "Deleting port $PORT_ID ..."
    openstack port delete "$PORT_ID" || true
  fi

  # detach (if somehow attached) and delete volume
  if [[ -n "$VOL_ID" ]] && openstack volume show "$VOL_ID" &>/dev/null; then
    echo "Deleting volume $VOL_ID ..."
    openstack volume set --read-only False "$VOL_ID" 2>/dev/null || true
    openstack volume delete "$VOL_ID" || true
  fi
  echo "--- cleanup done ---"
}

on_error(){
  local rc=$?
  echo "---- FAIL (rc=$rc). Last 80 log lines ----"
  tail -n 80 "$LOG_FILE" || true
  cleanup
  exit $rc
}
trap on_error ERR

# ============ Pre-flight ============
require_cmd openstack
require_cmd ssh-keygen

openstack flavor show "$WRK01_FLAVOR_NAME" >/dev/null || die "Flavor '$WRK01_FLAVOR_NAME' not found"
openstack image show  "$WRK01_IMAGE_ID"     >/dev/null || die "Image  '$WRK01_IMAGE_ID' not found"
openstack network show "$BAREMETAL_NET_ID"  >/dev/null || die "Network '$BAREMETAL_NET_ID' not found"
openstack subnet show  "$BAREMETAL_SUBNET_ID" >/dev/null || die "Subnet  '$BAREMETAL_SUBNET_ID' not found"

ensure_local_pubkey
ensure_os_keypair

# ============ Cloud-init (minimal) ============
USER_DATA_FILE="$(pwd)/${SERVER_NAME}_user_data.yaml"
cat > "$USER_DATA_FILE" <<'YAML'
#cloud-config
package_update: true
package_upgrade: false
runcmd:
  - echo "cloud-init completed" | tee /var/log/cloud-init-orchestrator.log
YAML

# ============ Volume ============
echo "Creating boot volume $BOOT_VOL_NAME from image..."
openstack volume create "$BOOT_VOL_NAME" \
  --size "$WRK01_BOOT_SIZE_GB" \
  --image "$WRK01_IMAGE_ID" >/dev/null
VOL_ID="$(openstack volume show "$BOOT_VOL_NAME" -f value -c id)"
echo "VOL_ID=$VOL_ID"
echo "Waiting for volume to be available..."
wait_for_status "openstack volume show $BOOT_VOL_NAME -f value -c status" "available" "$WAIT_SEC_VOLUME"

# ============ Port ============
echo "Creating baremetal port $BM_PORT_NAME ..."
openstack port create "$BM_PORT_NAME" \
  --network "$BAREMETAL_NET_ID" \
  --fixed-ip "subnet=$BAREMETAL_SUBNET_ID" \
  --disable-port-security >/dev/null
PORT_ID="$(openstack port show "$BM_PORT_NAME" -f value -c id)"
echo "PORT_ID=$PORT_ID"

# ============ Server ============
echo "Booting server $SERVER_NAME ..."
SERVER_ID="$(
  openstack server create "$SERVER_NAME" \
    --flavor "$WRK01_FLAVOR_NAME" \
    --volume "$BOOT_VOL_NAME" \
    --nic "port-id=$PORT_ID" \
    --key-name "$OS_KEYPAIR" \
    --user-data "$USER_DATA_FILE" \
    --property env="$ENVIRONMENT" \
    --property hyperscaler="$HYPERSCALER_TAG" \
    -f value -c id
)"
echo "SERVER_ID=$SERVER_ID"

echo "Waiting for server ACTIVE..."
wait_for_status "openstack server show $SERVER_ID -f value -c status" "ACTIVE" "$WAIT_SEC_SERVER"

echo "=== SUCCESS ==="
openstack server show "$SERVER_ID"
echo "Log: $LOG_FILE"
vsaravan@sjcvl-ghrunner1:~$
